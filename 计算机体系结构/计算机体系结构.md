## 计算机体系结构

**推荐书籍：**

计算机体系结构（第二版） 清华大学出版社

John L. Hennessy, David A. Patternson; Computer Architecture: A Quantitative Approach; sixth Edition. 

David A. Patternson, John L. Hennessy ; Computer Organization and Design- The Hardware/Software Interface; RISC-V Edition.

**参考书**：

CSAPP



## 考试

不要被填空题堵住了，不会做先做大题

### 题型

- 十题
- 填空题20分
- 九大题80分 最小5分 最大12分

### 题目

- 第七章

  - 开关

- 第六章

  - 向量优化，向量处理方式，哪种方式适合

- 第五章（填空、计算）

  - 理解相关性，怎样处理相关性
  - 针对计算流水性能分析，流水线的时空图的基本计算指标 加速比 吞吐率 效率等
  - 看清楚题目，是不是一个多滚轮的，动态静态多功能看清楚
  - 做一个简单算法，哪个先算哪个后算
    - 相同功能的要尽可能一起算
    - 尽可能减少RAW去除

- 第四章

  - 输入输出的三种基本方式
    - 程序控制
    - 中断（中断处理重点：中断优先级）
  - iop处理问题 通道 最大流量跟什么有关（工作周期互为倒数）
  - 使用通道的基本条件，实际流量不能超过通道最大流量，
  - 判断哪些通道与设备是否能连接

- 第三章 I/O
  - 几个层次
    - 每个层次的目标，扩容or提速
  - 如何地址变换提速
  - 如何 cache 性能优化
    - 减低失效率，减少时效冲突，减少命中时间
    - 替换算法   页 块  
      - 堆栈型替换算法怎么用
- 第二章 指令系统
  - 指令基本构成
  - 寻址方式 确定选择使用什么方式
    - 选择方法：频度分析
    - 间接寻址、变址寻址 -> 扩充寻址空间；立即寻址
  - 指令格式优化  分别对操作码操作数进行优化
  - 标记 下一条指令在哪 PC
  - CRSC RISC，了解RISC经常使用的技术
- 第一章
  - 计算：计算性能处理衡量cpu：CPI，计算过程中间有小的转弯
  - 阿姆达尔定理（部分改进对整体的影响），
    - 单部件优化的改善
    - 多部件的优化
  - 设计原理
    - 局部性原理（时间 空间局部性）



## 一、系统结构

- 体系结构要做的事情：

  - 从设计者角度，分析和评价 **系统性能/价格**

    - 在分析和评价的基础上，进行系统结构的设计

    - 系统结构的分析、设计和优化是本课程的重点



- 计算机体系结构的定义：
  - 程序员可见的计算系统的属性

  - 计算机体系结构研究如何设计、组织，以及使用可用的生产技术实现信息处理系统，该系统可有效地执行软件应用，满足价格、功耗和性能约束，最大化机器性能
  - 狭义观点：**软件设计者与硬件设计者之间的中间层，以及微体系**
  - 扩展观点：**算法层、语言层、系统软件层、ISA层、微体系结构、逻辑电路层**

- **计算机性能提高的原因：**

  - 科技：更多晶体管
    - 机器组织和实现
      - 更深的流水线 更多并行执行


  - 指令集架构
    - 精简指令集 拓展 显式并行


### 计算机系统结构概念

#### 计算机系统结构

系统结构(System Architecture)是对计算机系统中各机器之间界面的划分和定义，以及对各级界面上、下的功能进行分配

$$系统效率=\min(器件速度)*\min(系统结构效率)$$

![](assets/image-20230912151826216.png)

计算机体系结构是软件设计者与硬件设备设计者之间的中间层，是软件与硬件的接口

> **基本定义：程序员所看到的计算机的属性，即概念性结构和功能特性。**

透明性概念： 在计算机中，客观存在的事物或属性从某个角度看不到，称这些事物或属性对它是透明的。计算机重的“透明”与社会生活中的“透明” ，含义正好相反。

#### 计算机多层结构

1. 六级层次结构

   - 应用语言机器 面向用户

   - 高级语言机器 面向用户

   - 汇编语言机器 面向用户

   - 操作系统机器 面向上层机器

   - 传统机器 面向上层机器

   - 微指令机器 面向上层机器

2. 层次结构的实现方式
   - 根据性价比，软硬件逻辑是等同的

3. 分层优点

#### 计算机分类方式:star::star:

**并行度与并行体系分类**：数据级并行  任务级并行

计算机通过以下方式开发这两类应用并行：

1. **指令集并行**在编译器帮助下，利用流水线思想适度开发数据级并行
2. **向量体系结构和图形处理器 (GPU)** 将单条指令并行应用于一个数据集
3. **线程级并行**在一种紧搞合硬件模型中开发数据级并行或任务级并行
4. 请求级并行在程序员或操作系统指定的大量去搞合任务之间开发并行



- **按处理机性能分类**
- 按大小分类：<font color= red>**巨型、大型、中型、小型、微型机**</font>
  - 按照性能和价格分
- 按用途分：科学计算、事务处理、实时控制、工作站、服务器、家用计算机等。
  - 个人移动设备
  - 桌面计算，强调性价比
  - 服务器，强调可用性、可缩放性
  - 集群/仓储级计算机（Clusters / Warehouse Scale Computers）
    - 每个数据中心包含10+万个处理器核
    - X86-ISA兼容的服务器芯片在市场上占统治地位
    - 专门的应用程序，加上虚拟机的云托管
    - 现在越来越多地使用gpu、fpga和定制硬件来加速工作负载
    - 其分支:  Supercomputers：强调浮点运算性能和高速内部互联
    - 强调可用性和性价比(availability、price-performance、energy)
  - 嵌入式计算机/物联网（Embedded Computers / Internet of Things）
    - 有线/无线网络基础设施，打印机
    - 消费类产品( TV/Music/Games/Automotive/Camera/MP3)
    - 物联网（Internet of Things!)
    - 强调价格、能耗及面向特定应用的性能
- 按数据类型分：定点计算机、浮点计算机、向量计算机、堆栈计算机等
- 按处理机个数和种类划分：单处理机，并行处理机、多处理机、分布处理机，关联处理机，超标量处理机, 超流水线处理机, VLIW处理机，SMP(对称多处理机)、MPP(大规模并行处理机)、机群(Cluster)系统等
- 按所使用的器件划分：电子管、晶体管、集成电路、大规模集成电路

- 按“并行级”和“流水线”分类：Händler表示法

  - 根据可并行和流水处理的程度，将硬件分成三个层次：

    - 程序控制部件（PCU）的个数k；
    - 算术逻辑部件（ALU）或处理部件（PE）的个数d；
    - 每个算逻部件包含基本逻辑线路（ECL）的套数w。

  - 每一个计算机系统都可以用上述三个参数表示其结构特征，即：

    ​             t（系统型号）=（k，d，w）。

  - 为了更细致的反映结构特殊性，表示式可写成：

    ​              t（系统型号）=（k×k’，d×d’，w×w’），

  - 其中：k’表示宏流水线中程序控制部件的个数；
        d’表示指令流水线中算术逻辑部件的个数；
        w’表示操作流水线中基本逻辑线路的套数。

  - 各层次的数值越大越好。

- 按控制方式分类

  - 控制流方式：顺序执行 （冯·诺依曼型）
  - 数据流方式：操作数到位即可运算，无序执行
  - 规约方式：驱动方式与数据流相反，无序执行
  - 匹配方式：非数值型应用，主要对象为符号。
  - 对不同类型结构，并行程度越大越好。

- 按系统结构风格分类

  - 面向堆栈型、面向寄存器型、面向对象型等



##### 基于流（Flynn分类法）:star:

1. 模型中的重要概念

   指令流（Instruction Stream）：机器执行的指令序列；

   数据流（Data stream）：由指令处理的数据序列；

   多倍性（Multiplicity）：在系统最窄的部件上，处于同一执行阶段的指令和数据的最大可能个数。

2. 模型中的基本模块

   MM（Memory Module）：内存模块。

   PU（Process Unit）：处理单元

   CU（Control Unit）：控制单元

3. 按照指令流和数据流的多寡，Flynn将 CA 分成4种：

   1. **单指令流单数据流(SISD)**：一个CU从MM读取一个指令，并操控PU对MM操作
   2. **单指令流多数据流(SIMD)**：同一指令由多个使用不同数据流的处理器执行。开发数据级并行
   3. **多指令流单数据流(MISD)**:  目前为止，还没有这种类型的商用多处理器，但包含这种类型之后，这种简单的分类方式变得更完整。
   4. **多指令流多数据流(MIMD)**: 每个处理器都提取自己的指令，对自己的数据进行操作，它针对的是任务级并行。
   5. single program multiple data(SPMD)与single instruction multiple data(SIMD)都是可以处理多数据的，不同点是SIMD是从指令级上看的，这意味着SIMD处理的多数据是执行相同的操作，比如都执行加法。而SPMD是从程序级上看的，这意味着处理的多数据不一定是执行相同的操作，因为程序里面可以有分支等，即执行路径可以是多条。一句话，SIMD是多个数据执行相同的操作，SPMD是多个数据可以执行不同的操作也可以执行相同的操作。
   6. XIMD (variable instruction stream, multiple data stream) ： As an extension to the VLIW (Very Long Instruction Word) architecture, the XIMD can exploit all VLIW scheduling techniques but these do not take full advantage of the unique features of the XIMD
   7. 混合指令多数据(XIMD):所述XIMD计算系统可包括多个数据处理器，每个数据处理器代表单指令多数据(SIMD)计算系统的一条通道;其中，多个数据处理器被配置为使用第一主导通道执行指令，并在XIMD计算系统在执行程序期间遇到与第一主导通道不共享已取/未取状态的数据依赖指令时，分叉第二主导通道。

> 缺点：
>
> 1. 分类太粗
>
>    - 在SIMD中包括有多种处理机
>
>    - 对流水线处理机的划分不明确，
>
>    - 标量流水线为SISD，向量流水线为SIMD
>
>
> 2. 根本问题是把两个不同等级的功能并列对待     
>    - 数据流受指令流控制，造成MISD不存在
>
>
> 3. 非冯计算机的分类？其他新型计算机的分类

##### 库克分类法：按控制流和执行流分类:star:

(1)单指令流单执行流 (Single Instruction Single Executionstream, SISE) 典型的单处理机

(2)单指令流多执行流 (Single Instruction Multiple Executionstream, SIME)

- 多功能部件处理机、相联处理机、向量处理机、流水线处理机、超流水线处理机、超标量处理机、SIMD并行处理机

(3)多指令流单执行流 (Multiple Instruction Single Execution stream, MISE) 多道程序系统 

(4)多指令流多执行流 (Multiple Instruction Multiple Execution stream, MIME) 典型的多处理机

##### 冯氏分类法:star:

以最大并行度作为系统结构分类的标准，最大并行度的数值越大越好。

所谓最大并行度Pm是指一个系统在单位时间内能够处理的最多的二进制位数，显然这是一个完全由计算机硬件结构决定的参数。

- 字串位串（WSBS）：*n* = 1，*m* = 1。这是最早期全串行运算的计算机。

- 字并位串（WPBS）：*n* > 1，*m* = 1。这是传统的并行单处理机。

- 字串位并（WSBP）：*n* = 1，*m* > 1。每处理机只一位，但有许多个处理机字并行运用，如STARAN，MPP，DAP等。

- 字并位并（WPBP）：*n* > 1，*m* > 1。PEPE，ILLIAC Ⅳ，Cmmp等计算机属此类。

  ​         W – Word；B – Bit；S – Serial；P – Parallel

- 平均并行度

  - 如果在一个时钟周期$\Delta t_i$内实际处理的二进制位数为Pi，那么在T个时钟周期内的平均并行度Pa 就为：
    $$
    P_a=\left(\sum_{i=1}^T P_i\right) / T
    $$

  - 把平均并行度与最大并行度之比称为平均利用率，用μ表示为：
    $$
    \mu=P_a/P_m=\frac{\sum^T_{i=1}P_i}{T \bullet P_m}
    $$

### 系统结构设计

#### 计算机系统设计思路

1. **由上向下方法**：根据用户的要求，设计基本的命令、数据类型与格式等，然后再逐级往下设计，并考虑对上一级进行优化来实现

   - **适合于专用机的设计，从应用到实现级，周期几年。**

   - **缺点：当应用对象或范围变化时，效率急剧下降。**

   - **原因：软、硬件脱节，不能利用最新的软件技术。**

2. 由下向上方法：根据器件条件，先把微程序机器级及传统机器级研制出来，然后再配合不同的操作系统和编译系统软件，使应用人员根据所提供的条件来采用合适的算法满足相应的应用要求

   - 前提：硬件不能改变

   - 缺点：易形成软、硬脱节，软件不能获得最新硬件的支持，结果软件繁杂、效率低。

3. 从中间开始方法：

   - 从软、硬件交界面开始设计。
   - 要求首先进行软、硬件功能分配，同时考虑硬件能为软件提供什么支持。



#### 系统结构的设计步骤

1. 需求分析

2. 需求说明

   主要包括设计准则、功能说明、器件性能说明等。

3. 概念性设计

   进行软、硬件功能分析，确定机器级界面。

4. 具体设计

   机器级界面各方面的确切定义，可考虑几种方案。

5. 反复优化设计及评价

设计需求的转变：

1. Power Wall：以前能源便宜，晶体管贵；现在晶体管便宜，能源贵
2. ILP Wall：以前依靠编译器、架构创新来提高ILP (Out- of-order, speculation, VLIW)；现代利用ILP的好处变得越来越小
3. Memory Wall：以前乘法器慢，存储器速度快；现代相反
4. Power Wall + ILP Wall + Memory Wall = Brick Wall

#### 软硬件取舍原则

1. 现有软、硬件条件下，选择能提高**性价比**的方法；
2. 考虑到准备采用和可能采用的组成技术，所选方法能否尽量不限制组成和实现技术；
3. 不能仅从“硬”的角度去考虑如何便于应用组成技术的成果和发挥器件技术的进展，还应考虑所选方法能否从“软”的角度为编译和操作系统的实现，以至高级语言程序的设计提供更多更好的硬件支持。

硬件和软件在功能实现上是等效的，即一种功能可以由软件实现，也可以由硬件实现。在实现性能上是不等效的。软件实现的优点是设计容易、改进简单；硬件实现的优点是速度快。



### 计算机设计的定量原则

:star::star:常用的4个定量原理：

（1）以经常性事件为重点。在计算机系统的设计中， 对经常发生的情况，赋予它优先的处理权和资源使用权， 以得到更多的总体上的改进。

（2）Amdahl定律。加快某 部件执行速度所获得的系统性能加速比，受限于该部件在 系统中所占的重要性。

（3）CPU性能公式。执行一个程序所需的CPU时间 = IC ×CPI ×时钟周期时间。

（4）程序的局部性原理。程序在执行时所访问地址的分布不是随机的，而是相对地簇聚。



程序定位： • 把一个程序交给处理机运行，必须首先把这个程序的指令 和数据装入到主存储器中。一般情况下，程序所分配到的主存物理空间与程序本身的逻辑地址空间是不同的，把指令和数据中的逻辑地址(相对地址)转变成主存物理地址(绝对地址)的过程称为程序定位

- 使用抽象简化设计（表示层）
- 通过冗余实现可靠性；有了冗余，当中断发生时，系统仍能平稳运行
- 使用并行性：多处理器，磁盘，内存空，通道，多处理单元
- 性能方程



#### 如何使用并行性提高性能

- （超级）流水线
- 强大的指令
  - MD-technique：每次操作有多个数据操作数
  - MO-technique：每条指令执行多个操作
- 多指令问题
  - 单指令程序流
  - 多个流(或程序，或任务)


#### 局部性原则

- 一些重要的基本观察结果来自于程序的性质。
  - 程序在任何时刻都只能访问相对较小的地址空间。
- 局部性原则:程序倾向于重用它们最近使用过的数据和指令。
- 有两种不同类型的局部性
  - 时间局部性(局部性):如果一个道具被引用，它很快就会被再次引用(循环、重用等)。
  - 空间局部性(空间/位置中的局部性):如果一个项被引用，其地址彼此接近的项往往很快被引用(直线代码、数组访问等)。
- 根据一个程序过去的访问记录，我们可以相当准确地预测它在不久的将来会使用什么指令和数据。
- 一个程序将90%的执行时间花在10%的代码上

#### 专注于常见情况

- 更倾向于优化常见情况
  - 例如：指令提取和解码单元比乘法器使用频率更高，因此首先对其进行优化
  - 例如：如果数据库服务器有50个磁盘/处理器，存储可靠性高于系统可靠性，因此首先优化它明显有助于提高表现
  - 改善频繁事件，而不是罕见事件
- 频繁的情况通常比不频繁的情况更简单、更快地改善
  - 例如，当添加2个数字时溢出是罕见的，所以通过优化更常见的无溢出情况来提高性能
  - 可能会减慢溢出速度，但通过对正常情况的优化，整体性能有所提高
- 我们必须决定频繁的情况是什么，以及通过使情况更快可以提高多少性能=> Amdahl's Law



#### Amdahl's Law :star::star:

- Amdahl 定律定义了通过使用特定特性可以获得的性能提高
- 通过改进计算机的某些部件而获得的性能增益可以使用Amdahl定律来计算

$$
Speedup(E)=\frac{Execution\_Time\_Without\_Enhancement}{Execution\_Time\_With\_Enhancement}\\S_n=\frac{T_o}{T_n}=\frac{1}{(1-F_e)+\frac{F_e}{S_e}}
$$

其中：

$S_n$ —— 全局加速比；

$\mathrm{T_o} \longrightarrow $原执行时间(old) 一新执行时间(new)

$T_n$ —— 新执行时间

$S_e $ —— 被改进部分的局部加速比

$F_e $ —— 被改进部分原执行时间占原来总时间的百分比。



计算公式：改进之前程序运行总时间可写为: $T_o=T_o\left(1-F_e+F_e\right)$,改进之后由于其中部分操作加快, 总时间降为:

$T_n=T_o\left(1-F_e+\frac{F_e}{S_e}\right)$

根据加速比定义, 有: $S_n=\frac{T_o}{T_n}=\frac{1}{\left(1-F_e\right)+\frac{F_e}{S_e}}$

<img src="assets/image-20231222204935798.png" alt="image-20231222204935798" style="zoom:80%;" />



例题1：

例1-1：设改进后的某部件运行速度是原速度的10倍，而该部件原运行时间占全系统运行时间的比例为40%，那么此项改进会使全系统的性能得到多少提升？

解：按照Amdahl定律，系统性能的提升可以用加速比表示。据题意：Fe = 0.4；Re = 10，直接使用式（1-3），可得：

<img src="assets/image-20231108174829864.png" alt="image-20231108174829864" style="zoom: 33%;" />

<img src="assets/image-20231108174847365.png" alt="image-20231108174847365" style="zoom:50%;" />

<img src="assets/image-20231108174912003.png" alt="image-20231108174912003" style="zoom:50%;" />

1. 提高CPU的时钟频率，即减少CPI

   实现困难

   实用的考虑：体系结构设计者所作的工作不是进行元件级别的设计，但是可以选择元件，如果市面上没有所要求的元件或者价格太贵，则应考虑放弃这种方案；

   除非有实现元件级别改进的配套设备，否则不应该考虑开发新的元件。

2. 将CPU的流水线条数增加为n条，在理想情况下其运行速度可以提高n倍

   与上面同样的理由，因为速度相差太大，需要增加的流水线数目也相当大。

   一方面会给工艺上带来极大的困难，甚至达到不可能制作的地步（体系结构受到元件发展的限制）。

   另一方面如果流水线条数太多，指令的分配和调度也会带来许多困难，使实际效果大打折扣（得不偿失）。

3. 设计专门的多媒体指令及处理硬件，大幅度提高同一条指令处理大量数据的能力。



#### CPU性能公式:star::star:

- 时钟频率
- 时钟周期=1/时钟频率

一个程序的CPU时间为：
$$
\text{CPU时间} = \text{指令数} \times \text{CPI} \times \text{时钟周期时间} =程序的CPU时钟周期\times时钟周期时间=ncycle*Tcycle\\
\text{CPU时间} = \frac{\text{指令数} \times \text{CPI}}{\text{时钟频率}}
$$
指令计数（IC）

CPI: 平均每个指令的时钟周期

CPU性能依赖于：时钟周期时间、CPI 和 IC，它们是独立的



抽象简化设计

善用并行性

可靠性法则：没有单点故障的设计。

数据和指令的重复性使用



### 计算机性能标准

#### 衡量计算机性能的主要标准

计算机性能：**正确性、可靠性和工作能力**

工作能力指标：

- 处理能力—单位时间内能处理的信息量(吞吐率)。
- 响应能力—响应时间、周转时间、排队时间。
- 利用率—T时间内，某部分被使用时间t与T的比值。

CPU的能力：

- 硬件连接能力（主要是指速度指标）
  - CPU通过在引脚上设置数据、地址和控制总线实现与外部电路的连接，这种能力的强弱常用数据**总线带宽**，即单位时间内传输的数据量来表示。这是一个速度指标
  - 地址总线的宽度可以衡量CPU支持的容量指标。
- 数据带宽
  - CPU 引脚中数据总线的宽度乘以总线传输速率得到数据带宽
  - 例如，数据总线的传输速率为266 MHz，总线的宽度为32位（4字节），那么该数据总线的带宽就达到2.1GB/s（266MHz×4B）。
  - 体系结构改善：提高总线传输速率、增加总线宽度，相应的增加成本。

- CPU与Cache连接方式
  - CPU在片内连接Cache比在片外连接Cache具有更高的速度指标
  - CPU与Cache之间的数据通道越多，则速度越快
  - 一级CACHE集成在CPU同一芯片内，二级一般也在CPU同一芯片内，有的在芯片外；有的CPU还提供专门通道连结第三级CACHE。
  - 体系结构改善：为CACHE设计足够宽的通道、尽量把Cache设计在CPU芯片内，但是这会相应增加制造难度和成本。

**管理能力**（可靠性、速度、容量、可扩展性、性能价格比）：

- 其中对存储器的管理、对多道作业的管理、中断管理及对多处理机工作的管理能力尤其值得关注。


- 可靠性：多道作业管理

- 速度：Cache寻址，中断管理
- 容量：虚拟存储器寻址
- 可扩展性：中断管理
- 性能价格比：操作系统中某些软件功能放在硬件中实现，提高系统整体的性能价格比。

![image-20231108180121393](assets/image-20231108180121393.png)

![image-20231108180130060](assets/image-20231108180130060.png)

结论：

系统响应能力能反映计算机系统的软、硬件性能。不能仅用计算机主频衡量系统性能。



#### 系统处理能力

CPI的含义：以CPU为评估的模块，以指令系统中各条指令被执行的概率（频度）为依据，以平均每条指令所花费的时钟周期数标尺，对CPU的速度进行评估

CPI 不适合作为计算机系统整体的评估模块

可用的评价方式：基准测试，硬件，模拟，排队理论（分析模型），经验法则，基本“定律”/原则

##### MIPS和MFLOPS

- MIPS：每秒百万条指令数
  $$
  MIPS=\frac{指令条数}{执行时间\times 10^6}=\frac{时钟频率}{CPI\times 10^6}
  $$

- 缺点：

  - 只是反映了当前指令系统的前提条件下，指令执行的速度，不能反映指令的含金量，即不能反映指令系统本身的效率。
    - 例1：A系统1秒钟执行了100条指令，完成了应用程序TEST的全部功能，程序执行完毕；B系统1秒钟执行了1000条指令，完成了应用系统10%的功能，程序还没执行完。
    - 还不如直接使用应用程序总的执行时间来进行比较。
  - 没有考虑测试的全面性，如果没有一组用于测试的标准测试程序，那么该指标是没有可比性的。

![image-20231108180746607](assets/image-20231108180746607.png)



- MFLOPS（Million Floating Point Operations Per Second），被称为每秒百万次浮点运算。
  $$
  MFLOPS=\frac{MIPS}{每次浮点运算所需指令条数}，主要用于评估向量计算机
  $$

- 

- MFLOPS与MIPS关系：1MFLOPS≈3MIPS。



##### 基准测试程序

基准测试程序通常可以分为两类：

（1）一类用于测试系统中所用的元部件，如CPU（针对指令系统测试）、硬盘（针对IO操作测试）等，

（2）另一类则用来对全系统的性能进行测试（针对程序测试）。



##### 利用率

应用：利用阿姆达尔定律和程序局部性原理改进来提高部件利用率。



#### 性能评价技术

目的：可用于开发中和开发后的系统评价

种类：分为分析、模拟和测量

1. 分析技术
   - 方法：在一定假设条件下，计算机系统参数与性能指标参数之间存在着某种函数关系，按其工作负载的驱动条件列出方程，用数学方法求解。
   - 近似求解算法：聚合法、均值分析法、扩散法等。
2. 模拟技术
   - 按被评价系统的运行特性建立系统模型；
   - 按系统可能有的工作负载特性建立工作负载模型；
3. 测量技术
   - 评估层次：有实际应用程序、核心程序、合成测试程序三个层次。但必须均为国际性组织认可的程序。
   - 性能评价结果有峰值性能和持续性能两种。

#### 多机系统性能评价

1. 性能加速比
   $$
   S(p,n)=\frac{T(p,1)}{T(p,n)+h(p,n)}
   $$
   P问题大小，n处理机数，h为通信开销

2. 性能可伸缩性

   定义：对一个给定的应用问题，系统性能随PE数增加而线性增长的性能

   影响因素：PE数，时钟频率，问题大小，求解时间等。

   评价方法：选择某参考机作为比较参照机，测量后得出性能可伸缩性值。

### 计算机系统结构的发展

- 体系结构发展历史
  - Minicomputers,
  - Microprocessors
  - RISC vs CISC，VLIW 
- 体系结构现状及挑战
  - Denard Scaling 及 Moore’s Law 的终结
  - Security
- 体系结构发展机遇
  - Open Architectures 
  - Domain Specific Languages and Architecture
  - Agile Hardware Development
- 产品应用：– PC/Server => IoT, Mobile/Cloud
- 集成电路技术方面
  - 登纳德缩放比例定律的终结
    - 功耗成为关键制约条件
    - Stopped by threshold voltage
  - Moore定律的终结：晶体管的集成度提高延缓
    - 11 nm, 3 nm might be the limit



#### 冯·诺依曼机组系统结构的演变

**单处理器结构：**

1. 组成：由运算器、控制器、存储器、I/O设备组成

2. 特点 also called stored program computer

   - 采用存储程序原理

   - 指令串行执行，由控制器控制

   - 存储器按地址访问，是顺序的一维线性空间

   - 使用机器语言，数据以二进制表示

   - 单处理机结构，以运算器为中心

   - 输入输出设备与存储器之间的数据传送都途经运算器

![image-20231031163130567](assets/image-20231031163130567.png)

3. 缺点
   - 两个瓶颈：CPU—存储器，指令串行执行
   - 机器语言与高级语言间语义差别较大
   - 复杂数据结构必须经过地址映象存放
4. 改良
   - 程序运行中不允许被修改
   - 采用先行控制、流水线等方法，开发并行性
   - 采用多体交叉存储器，增加存储带宽
   - 增加新的数据表示，进一步支持高级语言
   - 以存储器为核心，使I/O设备和CPU可并行工作



**总线结构：**

- 总线： 连接计算机各功能部件的连线和管理信息传输规则的逻辑电路称为总线。
- 特点：在任何时刻，只能有一个部件向总线上发送信息，可以有多个部件同时接收信息。
- 组成： 数据总线、地址总线、控制总线。

![image-20231031164032899](assets/image-20231031164032899.png)



#### 非冯计算机的发展

- 从传统的指令驱动型改变为数据驱动型，出现了数据流机计算机
- 从传统的指令驱动型改变为需求驱动型，出现各种图归约计算机
- 处理非数值化信息的智能计算机，自然语言、声音、图形和图象处理,虚拟现实处理等
- 第五代计算机，由推理机和知识库机等组成。历经10年，召开过多次专题国际会议



#### 现代体系结构发展趋势：并行！！！

- 工艺发展的趋势

  - 芯片的集成度不断提高，但提升的速度在放缓
  - 时钟频率的提高在放缓，并有降低的趋势
- 体系结构的发展及机遇
  - 指令集并行受到制约
  - 线程级并行和数据级并行是发展的方向
  - 提高单处理器性能花费的代价呈现上升趋势
  - 面向特定领域的体系结构正蓬勃发展



### 系统结构中并行性

> :star:并行性概念：在同一时刻或同一时间间隔内完成两种或两种以上工作，只要在时间上相互重叠，均存在并行性。
>
> - 并行性：解题中具有可以同时进行运算或操作的特性。目的是为了能并行处理，提高解题效率。 
> - 广义并行性：只要在同一时刻或是在同一时间间隔内完成两种或两种以上性质相同或不同的工作， 在时间上能相互重叠，都称为并行性。
>
> 分类：
>
> - 同时性——指两个或多个事情在同一时刻发生的并行性
> - 并发性——指两个或多个事情在同一时间间隔内发生的并行性

#### 并行性等级

- 从执行角度分

  - 指令内部并行，即指令内部的微操作之间的并行；（硬件和组织的设计）

  - 指令间并行，即并行执行两条或多条指令（处理好指令间的关联  ILP）

  - 任务级或过程级并行，即并行执行两个或多个过程或任务（程序段 TLP）（任务分解）

  - 作业或程序级并行，即在多个作业或程序间的并行（并行算法）

- 从数据处理角度：位串字串  位并字串  位片串字并  全并行 

- 从信息加工角度 

  - 存贮器操作并行； 处理器操作步骤并行； 处理器操作并行；  指令、任务、作业并行

#### 提高并行性的技术途径:star::star:

- 时间重叠
  - 多个处理过程在时间上相互错开，轮流重叠使用同一套硬件的各个部件，以加快部件的周转而提高速度
  - 举例：流水线——分离、细化功能部件→流水线→功能不同的多机系统→异构型多处理机系统
- 资源重复
  - 以数量取胜原则，重复设置硬件资源以大幅度提高计算机系统的性能
- 资源共享
  - 利用软件方法，使多个用户分时使用同一个计算机系统。例如多道程序、分时系统就是资源共享的产物。它是提高计算机系统资源利用率的有效措施。 
  - 多道程序、分时OS →真正的处理机代替虚拟机→分布处理系统

#### 并行处理的发展

##### 单机系统中并行处理的发展

- 单处理机并行性开发的主要途径是**时间重叠**。
- 实现时间重叠的基础是**部件功能专用化**。
- 将一件工作按功能分割成若干联系的部分，每一部分有指定的专门部件来完成，然后按时间重叠的原则把各部分执行过程在时间上重叠起来，使所有部件依次分工完成一组同样工作。   


> 将若干台具有独立功能的处理机（或计算机）相互连接起来，在操作系统（或分布式操作系统）的控制下，统一协调的运行，这就是**分布式处理系统（distributed processing system）** 。
>
> 分时系统是以“集中”为特征，分布系统是以“分布”为特征。 

##### 多机系统中并行处理的发展 

- 多计算机系统：多台独立的计算机构成的系统。
- 多处理机系统：多台处理机构成的系统

耦合（耦合度是反映多机系统中各机器之间物理连接的紧密程度和交互作用能力的强弱 ）：

- 最低耦合：仅通过中间存储介质互相通信，除此之外，各机器间并无物理连接，也无共享的联机硬件资源 。例如：磁带
- 松散耦合（间接耦合）：机器之间是通过通道或通信线路实现互联，共享某些外围设备。特点：通信频带较低；例如：计算机网络
- 紧密耦合（直接耦合）：通过总线或高速开关实现互连，共享主存储器，机器间通信频率高，信息传输率和吞吐量大。

两种典型的松散耦合形式：

- 多台计算机通过通道和共享的外围设备连接，各个机器实现功能专用化，机器处理结果以文件和数据集合形式送到共享外设，供其他机器调用，从而获得较高的系统使用效率；
- 各节点计算机通过计算机网络连接，在网络操作系统管理下，合理调度软、硬件资源，以求得更大范围内资源共享。 



- 同构型多处理机是把一道程序（作业）分解为若干相互独立的程序段或任务，分别有各个处理机并行执行。
- 异构型多处理机是将作业分解成串行执行的若干个任务，分别有不同功能的处理机分工完成，依靠流水作业的原理，对多个作业重叠地进行处理。
- 分布处理系统各处理机尽量完成本地作业，当其资源和能力不够时才与其他处理机协同。 



## 二、指令系统 (Instruction Set)

### 指令系统概述

- IS 是计算机体系结构的主要组成部分
- IS 标识硬件和软件之间的接口
- IS 是通信硬件和软件之间的桥梁
- 信息系统和软件之间的语义差异越来越大
- 一个指令系统是使用处理器的基本方法

**指令**是处理器进行操作的最小单元，如加减乘除、读写存储器操作

指令系统**设计原则**：加快经常性事件

大多数指令系统都很相似，只有少数不同的不同的方式去操作数据，有流行的指令架构，但其他也不能忽视。



### 数据

#### 数据类型

定义：具有一组**值的集合**，且定义了作用于该集合的操作集

目的：防止不同类型数据间的误操作，为了满足软件的需求，是计算机软件系统需要使用的。

分类：基本类型、结构类型

**基本数据类型**：二进制位、二进制位串、整数、十进制数

**结构数据类型：由一组相互有关的数据元素复合而成的数据类型**，数组、字符串、向量、堆栈、队列、记录等

> **大多数系统结构只能部分地支持结构数据类型**



#### 数据表示

DR (data representation) 是电脑硬件可以直接识别的，可以直接被指令系统使用的。

需要确认哪些 DS 是使用 DR 实现的，使用 DR 的数据类型更高效，DR决定怎么选择软硬件

数据类型的确定原则：

- 减少程序运行实践
- 减少CPU和内存间通信
- 数据类型的普遍和实用效率

DR 是在发展和扩大的，实现新的DR可以更好的使用软硬件

高质量的数据表示：栈、向量、数组等

目标：支持数据结构，提高系统有效性和性能/价格。



> 例：实现A＝A＋B，A和B均为200×200的矩阵，分析向量数据表示的作用
>
> 解：如果在没有向量数据表示的计算机系统上实现，一般需要6条指令，其中有4条指令要循环4万次。因此，CPU与主存储器之间的通信量：
>   取指令2＋4×40,000条，
>   读或写数据3×40,000个，
>   共要访问主存储器7×40,000次以上。
>
> 如果有向量数据表示，只需要一条指令。
>
> 减少访问主存（取指令）次数：4×40,000次
>
> 缩短程序执行时间一倍以上。



**数据表示增加的原则：**

1. 是否提高了系统的有效性

   是否减少实现时间，是否减少专用空间。例如:向量被操纵A=A+B，当采用向量数据表示时，矢量算法组件管道计算可以节省时间，辅助开销时间减少;

2. 数据表示是否具有通用性和利用率就足够了

   通用性：是否适用于多种数据结构。

例子：增加树结构数据类型还是指针数据类型

- 树结构对向量、数组等支持不好
- 更好支持多种数据结构
- 出现选择困难的时候依据 性能/价格比



**DS与DR的关系：**

- 

- DR 是 DS 的子集
- DR 是软硬件的接口，DS 属于软件程序

![image-20231211082431724](assets/image-20231211082431724-17022542740091.png)



#### 自定义数据表示

数据存储单元（寄存器、主内存储器、外存储器等）仅存储纯数据。

- 由指令中的运算符解释的：数据类型(定点，浮点，字符，字符串，逻辑，矢量等)进位系统(2、10、16等)
- 数据字长(字、半字、双字、字节等)
- 寻址方式(直接寻址，间接寻址，相对寻址，寄存器寻址)
- 数据功能(地址，数值，控制字，符号等)
- 相同类型的操作(在加法的情况下)

有很多指令在高级语言和应用软件中，数据的属性是由数据本身定义的，高质量语言和机器语言之间的语义差异由编译器来解决。

- 60年开始，Burroughs公司引进了自定义的数据表示方式，数据表示方式包括符号



##### 带数据标识符的数据表示

目的：为了减少高级语言和机器语言的差异，减少数据分类

实现：编译器建立，由硬件完成转换

例子：

![img](assets/20200227230742.png)

> 功能位：操作数、指令、地址、控制字
> 陷井位：由软件定义四种捕捉方式
> 封写位：指定数据是只读的还是可读可写
> 类型位：二进制,十进制,定点数,浮点数,复数,字符串,单精度,双精度；绝对地址、相对地址、变址地址、未连接地址等。

**标志符的处理机所占用的存储空间通常要小**

![img](assets/20200227231722.png)

通过合理的设计可以让橙色框比紫色框小

标识符数据表示方法的[优点]：

- 简化了指令系统。

- 由硬件实现一致性检查和数据类型转换。
- 简化程序设计，缩小了人与计算机之间的语义差距。
- 简化编译器，使高级语言与机器语言之间的语义差距大大缩短。
- 支持数据库系统，一个软件不加修改就可适用于多种数据类型。
- 方便软件调试，在每个数据中都有陷井位。

[缺点]：

- 数据和指令长度可能不一致：可以通过精心设计指令系统来解决
- 指令[执行速度]降低，但是采用标志符设计，程序的设计编译调试实践都会降低
- 硬件复杂度增加



##### 数据描述符

数据描述符与标志符的**区别**：标志符只作用于一个数据，而**数据描述符要作用于一组数据**

![image-20231010151645522](assets/image-20231010151645522.png)

举个栗子：
$$
A=\left[\begin{array}{llll}
a_{11} & a_{12} & a_{13} & a_{14} \\
a_{21} & a_{22} & a_{23} & a_{24} \\
a_{31} & a_{32} & a_{33} & a_{34}
\end{array}\right]
$$
<img src="assets/image-20231010152134805.png" alt="image-20231010152134805" style="zoom:67%;" />

第一行的3表示有三个这样的数据（组）并且存了他们的起始地址（**这一行是用来描述之后数据类型的（比如说三个单行数组）**）；后三个101表示每一组数据有4个数据并且存了他们（数据）的起始地址（**这几行是用来描述具体数据的（描述单行数组中的数据）**）；后面就是顺序存放的数据





### 指令

组成：操作 + 源地址 + 目标地址 + 下一个指令地址

类型：数据的处理、存储、移动、程序的流程控制



#### 操作数

- 操作数类型和操作数表示是软硬件的主要界面之一。
- 操作数类型：是面向应用、面向软件系统所处理的各种数据类型。
  - 整型、浮点型、字符、字符串、向量类型等
  - 类型由操作码确定或数据附加硬件解释的标记，一般采用由操作码确定
  - 数据附加硬件解释的标记，现在已经不采用
- 操作数的表示：操作数在机器中的表示，硬件结构能够识别，指令系统可以直接使用的表示格式
  - 整型：原码、反码、补码
  - 浮点：IEEE 754标准
  - 十进制：BCD码/二进制十进制表示

常用操作数类型：

- ASCII character = 1 byte (64-bit register can store  8 characters
- Unicode character or Short integer = 2 bytes = 16 bits （half word) 
- Integer = 4 bytes = 32 bits (word size on many RISC Processors)
- Single-precision float = 4 bytes = 32 bits (word size)
- Long integer = 8 bytes = 64 bits (double word)
- Double-precision float = 8 bytes = 64 bits (double word)
- Extended-precision float = 10 bytes = 80 bits (Intel architecture)
- Quad-precision float = 16 bytes = 128 bits



#### 指令结构分类

分类准则：

1. CPU中操作数的存储方法分类
2. 指令中显式操作数个数分类
3. 根据操作数能否放在存储器中分类

指令集划分成堆栈、累加器、寄存器型三类



#### 常见指令集

- MIPS
- SPARC
- Alpha
- ARMv7
- ARMv8
- OpenRISC
- 80x86



### 寻址方式

定位操作数和其他信息的位置称为寻址

**采用多种寻址方式可以显著地减少程序的指令条数，但可能增加计算机的实现复杂度以及指令的CPI。**



重要的寻址方式:

- 偏移寻址方式, 立即数寻址方式, 寄存器间址方式
- SPEC测试表明，使用频度达到 75%--99%

偏移字段的大小应该在 12 - 16 bits

- 可满足75%-99%的需求

立即数字段的大小应该在 8 -16 bits

- 可满足50%-80%的需求



**尾端问题：**

如地址 xxx00 指定了一个字（int）, 存储器中从 xxx00 处连续存放 ffff0000, 则有两种方式：

–Little endian 方式下 xxx00 位置是字的最低字节，整数值为0000ffff, Intel 80x86, DEC Vax, DEC Alpha (Windows NT)

–Big endian 方式下xxx00位置是字的最高字节，整数值为ffff0000, IBM 360/370, Motorola 68k, MIPS, Sparc, HP PA



**对齐问题：**

对s字节的对象访问地址为A，如果 $A \, {\rm mod} \, s =0$，则称为边界对其，

如果边界没有对其，就可能访问一个对象需要读取两次寄存器，也可能会引发异常

![image-20231012102609291](assets/image-20231012102609291.png)



**编址方式：**

编址单位：

- word、byte、bit、block等

- 一般：字节编址，字访问

  - 部分机器：位编址，字访问
  - 辅助存储器：块编址

- **Number of zero address space**

  - **三个零地址空间**：通用寄存器、主存储器和输入输出设备均独立编址
  - **两个零地址空间**：主存储器与输入输出设备统一编址
  - **一个零地址空间**：所有存储设备统一编址，最低端是通用寄存器，最高端是输入输出设备，中间为主存储器
  - **隐含编址方式**，实际上没有零地址空间：堆栈、**Cache等**

- 对于I/O设备

  - 一个地址一个设备：必须通过指令中的操作码来识别该输入输出设备上的有关寄存器
  - 两个地址一个设备：一个地址是数据寄存器，一个地址是状态/控制寄存器
  - 单设备多地址：对编程增加困难

- 对于并行内存

  - 高位交叉编址  主要目的是用来扩大存储器容量。

    ![image-20231012145133654](assets/image-20231012145133654.png)

  - 低位交叉编址  主要目的是提高存储器速度。

    ![image-20231012145144785](assets/image-20231012145144785.png)



**寻址方式**

1. 寄存器寻址（Register）
2. 立即数寻址（Immediate or literals）
3. 偏移寻址（Displacement）
4. 寄存器间接寻址（Register deferred or indirect）
5. 索引寻址（Indexed）
6. 直接寻址或绝对寻址（Direct or absolute）
7. 存储器间接寻址（Memory indirect or memory deferred）
8. 自增寻址（Auto increment）
9. 自减寻址（Auto decrement）
10. 缩放寻址（Scaled）



寻址方式的设计思想

- 立即数寻址方式，用于数据比较短、源操作数
- 面向寄存器的寻址方式
- 面向主存储器的寻址方式
- 面向堆栈的寻址方式



虚地址或有效地址被偏移到段中

- 起始地址加上偏移量得到线性地址
- 如果启用了分页，则会进行页面转换



**指令格式**

- 许多电脑支持超过一种指令格式
- 电脑能支持可变长的指示

指令格式长度与数据总线宽度相关联

- 指令小于数据总线大小：32位总线上的16位指令，单次可以读取多个指令
- 指令比数据总线宽：需要对整个指令进行多次读取



指令集在支持的**指令格式**方面有所不同

指令格式的主要区别在于它们所使用的**操作数的数量和类型**。



**指令长度**

被下列所影响：

- 内存大小
- 内存组织形式
- 总线结构
- CPU 复杂性
- CPU 速度

在高效指令和空间大小中均衡



**指令格式设计**

只包含以下两种指令格式的设计方式：

格式A：Reg, Reg: R1 <- R1 OP R2

格式B：Reg, Mem: R1 <- R1 OP Mem



**使用频带分析法，根据指令系统风格和各种寻址方式的使用频率，选择高频率的寻址方式。**



**位移寻址模式**

基准测试显示 12bit 位移可以代替 75% 的32bit位移，16bit 可以代替 99%



#### 程序的装入

将程序(模块)装入内存时，可以有三种方式：

- 绝对装入方式
  - 编译时知道程序在内存中位置，产生绝对地址
  - 地址不需要修改
- 可重定位装入方式(静态重定位方式)
  - 在装入时对程序中逻辑地址的偏移值加入起始地址中

  - 在装入时一次完成

  - 只能连续装入
- 动态运行时装入方式
  - 优点：主存利用率高，多个用户可以共享同一个程序段，支持虚拟存储器实现。   
  - 缺点：需要硬件支持，实现的算法比较复杂



### 优化指令格式

目标：

- 节省程序存储空间
- 指令格式尽量规整，便于译码

方法：

- 操作码的优化表示；地址码的优化表示



#### 优化操作码

三种方法：固定长度，哈夫曼编码，扩展编码

主要使用 Huffman 编码：

每个字符最少所需要的位数：
$$
H=-\sum_{i-1}^nP_i \cdot \log_2P_i
$$
$P_i$表示第$i$个数出现的概率的排序

固定长度编码冗余：
$$
\mathrm{R}=1-\frac{-\sum_{\mathrm{i}=1}^{\mathrm{n}} \mathrm{P}_{\mathrm{i}} \cdot \log _2 \mathrm{P}_{\mathrm{i}}}{\left\lceil\log _2 \mathrm{n}\right\rceil}
$$
使用变长编码的时候我们要极其注意冲突问题

对树的边进行标记，使通向左子结点的边被赋值为0，通向右子结点的边被赋值为1。

在一个树上，没有一个字符的编码可以是另一个字符的祖先，因此一个字符的编码不可能是另一个字符的前缀



计算 Huffman 方法：

- 对于n个字母的字母表，Huffman 算法从第n个节点开始，标记字母和其频率
- 我们确定两个具有最低频率的顶点，并将它们替换为树，其根标记为这两个频率的和，其两个子节点是我们替换的两个顶点。



<<<<<<< HEAD
缺点：

- 操作码长度不规整，硬件译码苦难
- 与地址码共同组成固定长的指令比较困难





扩展编码法：由固定长操作码与Huffman编码法相结合形成

![image-20231016144657727](assets/image-20231016144657727.png)

扩展方法：等长扩展和不等长扩展两种。

扩展编码中选择某些特征位用于扩展。

注意扩展目标(各频率段)间关系。

![image-20231016144812788](assets/image-20231016144812788.png)



不等长扩展：

例3：指令系统共有78种指令，前10种使用频率平均为0.049，中间18种使用频率平均为0.02，最后50种使用频率平均为0.003。如何编码？

同上例方法，码长可有三种；

因每段指令数比例为1：2：5，故不可采用等长扩展，采用不等长编码( 4-6-10位)较能减少平均码长。



### 编译器优化

编译器目标：

- 所有程序都被正确编译
- 大多数编译程序执行更快
- 快速编译
- 支持调试



优化类型

高级——在源代码级别或接近源代码级别完成

- 如果过程只被调用一次，则将其内联并保存CALL
- (更一般的情况):如果 call-count < 某个阈值，则将它们内联

本地——完成的直线代码

- 公共子表达式产生相同的值——要么分配一个寄存器，要么用一个副本替换
- 常量传播——用常量替换常量值变量
- 堆栈高度缩减——重新安排表达式树以最小化临时存储需求

全局—跨分支

- 复制传播——将赋值为X(即a =X)的变量a的所有实例替换为X。
- 代码移动-从循环中删除每次循环计算相同值的代码，并将其放在循环之前
- 简化或消除循环中的数组寻址计算

依靠机器优化

- 长度减少——通过移位和加法减少乘法
- 管道调度
- 分支偏移优化-重新排序代码以最小化分支偏移



编译器技术综述

- 尽量避免依赖停滞
- 循环展开-减少循环开销
- 软件流水线-减少单体依赖失速
- 跟踪调度-减少其他分支的影响
- 编译器混合使用三种
- 所有的技术都依赖于预测的准确性



### 指令系统的功能设计

要求：完整性、规整性、高效率和兼容性

- 完整性：是指应该具备的基本指令种类，通用计算机必须有５类基本指令
- 规整性：包括对称性和均匀性对称性：所有寄存器同等对待，操作码的设置等都要对称，如：A－B与B－A
- 均匀性：不同的数据类型、字长、存储设备、操作种类要设置相同的指令
- 高效率：指令的执行速度要快；指令的使用频度要高；各类指令之间要有一定的比例
- 兼容性：在同一系列机内指令系统不变（可以适当增加）

当前对这一问题的处理有两种截然不同的方向：CISC和RISC

1. 复杂指令系统计算机CISC(Complex Instruction Set Computer)增强指令功能，设置功能复杂的指令面向目标代码、高级语言和操作系统用一条指令代替一串指令

   2. 精简指令系统计算机RISC(Reduced Instruction Set Computer)只保留功能简单的指令功能较复杂的指令用子程序来实现



CISC指令系统存在的问题：

1. 20％与80％规律
   CISC中，大约20％的指令占据了80％的处理机时间。其余80％指令：使用频度只占20％的处理机运行时间

2. VLSI技术的发展引起的问题
   VLSI工艺要求规整性RISC正好适应了VLSI工艺的要求主存与控存的速度相当简单指令没有必要用微程序实现，复杂指令用微程序实现与用简单指令组成的子程序实现没有多大区别；由于VLSI的集成度迅速提高，使得生产单芯片处理机成为可能。

3. 软硬件的功能分配问题

   复杂的指令使指令的执行周期大大加长一般CISC处理机的指令平均执行周期都在4以上，有些在10以上



> 减少CPI是RISC思想的精华

程序执行时间的计算公式：
$$
P = I· CPI · T
$$
其中：P是执行这个程序所使用的总的时间；I是这个程序所需执行的总的指令条数；CPI (Cycles Per Instruction)是每条指令执行的平均周期数T是一个周期的时间长度。

RISC的速度要比CISC快3倍左右，关键是RISC的CPI减小了

![image-20231016153320452](assets/image-20231016153320452.png)



### ISA (Instruction Set Architecture) 

指令集架构 (ISA) 是计算机抽象模型的一部分，它定义了**软件如何控制 CPU**。 

ISA 充当硬件和软件之间的接口，指定处理器能够做什么以及如何完成。

ISA 提供了用户与硬件交互的唯一方式。它是机器中对汇编语言程序员、编译器编写者和应用程序程序员可见的部分。

<img src="assets/image-20231210212348970.png" alt="image-20231210212348970" style="zoom:50%;" />

ISA 应当具备**特性**：

- 成本低
- 简洁性
- 架构和具体实现分离：可持续多代，以保持向后（backward) 兼容
- 易于编程/链接/编译

**优秀的 ISA **所具有的**特征**：

- 可持续用于很多代机器上(portability)
- 可以适用于多个领域 (generality)
- 对上层提供方便的功能（convenient functionality)
- 可以由下层有效地实现（efficient implementation )



**IBM 360 是第一个将 ISA 与其实现分离的机器，一个 ISA 可能由不同的实现方式**



ISA 需要描述的内容：

- 内存地址
- 取址方式
- 操作数的类型和大小
- 操作符



ISA 定义了支持的数据类型、寄存器、硬件如何管理主内存、关键功能（例如虚拟内存）、微处理器可以执行哪些指令以及多个 ISA 实现的输入/输出模型。可以通过添加指令或其他功能，或者添加对更大地址和数据值的支持来扩展 ISA。



- 重要的系统界面（System Interface）
  - ISA界面（Instruction Set Architecture）
  - ABI界面（Application Binary Interface）

- ISA：用户级ISA+特权级ISA
  - 用户级ISA 适用于操作系统和应用程序
  - 特权级ISA 适用于硬件资源的管理（操作系统）



#### ISA 的实现

![image-20231010142433457](assets/image-20231010142433457.png)









## 三、存储系统

大纲：

1. 存储系统的**构成机制与性能优化**
2. 虚拟存储器（cache）的**工作原理与主要设计思考**
3. **地址的映象和变换方法及优化**
4. 页面（cache块）**替换算法及其实现**
5. 虚拟存储器（Cache）**性能的优化方法**
6. 一致性问题研究
7. 存储系统实例研究





### 存储系统原理

种类：主存储器、Cache、通用寄存器、缓冲存储器、磁盘存储器、磁带存储器、光盘存储器等。

- RAM：代表随机访问内存因为你可以通过地址访问内存，读写内存；被称为 DRAM (dynamic RAM) ；电容器失去电荷，因此必须经常充电(每隔几毫秒)，并且具有破坏性读取，因此必须在读取后充电
- Cache：SRAM（static RAM），比寄存器慢，因为增加了寻找正确缓存位置的电路，但比RAM快得多；DRAM比SRAM慢10-100倍
- ROM：只读存储器，有几个变种

材料工艺：ECL、TTL、MOS、磁表面、激光，SRAM，DRAM。

访问方式：随机访问、直接译码、先进先出、 相联访问、 块传送、文件组。



RAID 对比：

![image-20231017141828613](assets/image-20231017141828613.png)



存储器的主要性能：**速度、容量、价格。**

- **速度**用存储器的访问周期、读出时间、频带宽度等表示。

- **容量**用字节B、千字节KB、兆字节MB和千兆字节GB等单位表示。

- **价格**用单位容量的价格表示，例如：$C/bit。


- **组成存储系统的关键**：把速度、容量和价格不同的多个物理存储器组织成一个存储器，这个存储器的**速度最快，存储容量最大，单位容量的价格最便宜。**



**存储系统的定义：**

- 两个或两个以上速度、容量和价格各不相同的存储器用硬件、软件、或软件与硬件相结合的方法连接起来成为一个存储系统。
- 这个存储系统对应用程序员是透明的，并且，从应用程序员看，它是一个存储器，这个存储器的速度接近速度最快的那个存储器，存储容量与容量最大的那个存储器相等，单位容量的价格接近最便宜的那个存储器。

虚拟存储器系统：对应用程序员透明

- 由主存储器和硬盘构成

- 目的：扩大存储器容量

  ![image-20231017144024343](assets/image-20231017144024343.png)

Cache存储系统：对系统程序员以上均透明



- 存储系统设计是计算机体系结构设计的关键问题之一
  - 价格，容量，速度的权衡
- 用户对存储器的“容量，价格和速度”要求是相互矛盾的
  - 速度越快，每位价格就高
  - 容量越大，每位价格就低
  - 容量越大，速度就越慢
- 目前主存一般由DRAM构成



理想情况：

- 0延迟
- 无限体积
- 零花费
- 无限带宽（支持多路并行访问）

以上理想是互相矛盾的，ex: 体积越大 速度越低



#### 局部性原理

缓存利用了局部性原则

一些技术:记忆翻译;保护和虚拟化内存管理单元(MMU)

- 转换:虚拟地址到物理地址的映射
- 保护:访问内存地址的权限
- 虚拟化:使用磁盘透明地扩展内存空间



![image-20231017143328357](assets/image-20231017143328357.png)

![image-20231017143350917](assets/image-20231017143350917.png)



存储层次工作原理：**局部性**

应用程序局部性原理: 给用户

- 一个采用低成本技术达到的存储容量. （容量大，价格低）
- 一个采用高速存储技术达到的访问速度.（速度快）

Temporal Locality (时间局部性):

- =>保持最近访问的数据项最接近微处理器

Spatial Locality (空间局部性):

- 以由地址连续的若干个字构成的块为单位，从低层复制到上一层



#### 存储系统容量

要求：

1. 尽可能大的地址空间
2. 能够随机访问

方法有两种：

- 只对系统中存储容量最大的那个存储器进行编址，其他存储器只在内部编址或不编址。
  - Cache存储系统。
- 另外设计一个容量很大的逻辑地址空间，把相关存储器都映射这个地址空间中。
  - 虚拟存储系统



#### 存储系统的速度

访问周期、存取周期和存取时间等

- 命中：访问的块在存储系统的较高层次上
  - 命中率：存储器访问较高层次命中的比例 $H=N_1/(N_1+N_2)$
  - 命中时间：访问较高层的时间
- 失效：访问的块不在存储系统的较高层次上
  - 失效：$1-(Hit\ Rate)=1-H=N_2/(N_1+N_2)$
  - 当在M1中没有命中时：一般必须从M2中将所访问的数据所在块搬到M1中，然后CPU才能在M1中访问。
  - 设传送一个块的时间为TB,即不命中时的访问时间为：TA2+TB+TA1 = TA1+TM
  - TM 通常称为失效开销Miss Penalty 
- 访问周期与命中率的关系：
  - 平均访存时间  TA = HTA1+(1-H)(TA1+TM) = TA1+(1-H)TM
  - 当命中率H→1时，T→ TA1




34页开始没做





#### 存储系统的层次结构

3.1.3 存储系统的频带平衡
3.1.4 并行访问存储器
3.1.5 交叉访问存储器
3.1.6 无冲突访问存储器



### 虚拟存储器

#### 虚拟缓存器工作原理

把主存储器、磁盘存储器和虚拟存储器都划分为固定大小的页：

- 主存储器的页称为实页
- 虚拟存储器中的页称为虚页

#### 地址的映象和变换方法

#### 加快内部地址变换的方法

#### 页面替换算法及其实现

#### 提高主存命中率的方法

### 高速缓冲存储器(Cache)



### 三级存储系统

- 虚拟存储系统和Cache 存储系统可同时存在
- 存储系统可以有多种构成方法，不同的构成只是实现技术不同

![image-20231109142540760](assets/image-20231109142540760.png)

既有虚拟存储器又有Cache系统：

- 虚拟存储器次啊用**位选择组相联方式**
- 虚拟存储器中的一页等于主存储器的一个区
- 用虚拟地址中的虚页号访问快表





## 四、输入输出系统

本章重点：

1. 了解三种基本输入输出方式的原理及特点。

2. 中断系统中的软硬件功能分配。

3. 中断优先级和中断屏蔽的原理及方法。

4. 通道中的数据传送过程与流量分析。

5. 输入输出处理机的作用及种类。



输入/输出系统简称I/O系统

- I/O 设备
- I/O 设备与处理机的连接



### 引言

指令系统设计原则：**加快经常性事件**

- CISC和RISC思路都是加快经常性事件
- 加快经常性使用的指令是RISC的核心思想

加快方法：**并行（Parallel)**

1、流水线技术（指令流水线，指令时间并行）
2、多指令流出技术（指令空间并行）
3、向量机（数据流水线，数据时间并行）
4、SIMD（单指令多数据，数据空间并行）



存储系统设计原则：**加快经常性事件、与CPU性能匹配**

加快方法：**系统**

- cache存储系统（将经常访问的数据放在cache中）
- 虚拟存储系统（将经常访问的数据放在内存中）



I/O设备接口的两种策略：

- 内存映射
  - I/O 设备作为处理器内存的一部分
  - 读写I/O设备位置，配置I/O和传输数据(使用编程I/O或DMA)

- I/O 通道
  - 特殊指令在指定的通道上执行I/O命令
- **同步问题**
  - 轮询：CPU检查状态字节
  - 中断：设备通过事件中断CPU



#### I/O系统性能

如何评价 I/O 性能：

- 连接特性 容量 响应时间 吞吐率 

另一种衡量I/O系统性能的方法：

-  考虑I/O操作对CPU的打扰情况。
-  即考查某个进程在执行时，由于其他进程的I/O操作，使得该进程的执行时间增加了多少。 



影响I/O性能的方面有很多，但是有两个主要方面：

- 吞吐量：I/O带宽
- 响应时间：延时



##### 简单 Producer-Server 模型

![image-20231107143558675](assets/image-20231107143558675.png)

- 吞吐量：

  - 服务器在单位时间之间内完成的任务

  - 为了获得尽可能高的吞吐量
    - 服务器不应该处于空闲
    - 队列不应该是空的


- 响应时间
  - 任务放入队列时开始，在被服务完成时结束
  - 最小化响应时间
    - 队列应该是空的
    - 服务应该处于空闲状态

*吞吐量* 和 *响应时间* 的函数应该是指数增长的



一般来说，吞吐量可以通过以下方式提高:

- 投入更多硬件
- 减少与负载相关的延迟

响应时间更难减少:

- 最终它会受到光速的限制(但我们离光速还很远)



##### 响应时间

- 系统响应时间 = I/O系统的处理时间 + CPU的处理时间
- **多线程技术**只能提高系统吞吐率，并不能减少系统响应时间
- 进程切换时可能需要增加I/O操作
- 可切换的进程数量有限，当I/O处理较慢时，仍然会导致CPU处于空闲状态

![image-20231107203626014](assets/image-20231107203626014.png)



##### 连接特性

物理上的规定和标准只要是需要互联的，必须各方面一致，否则无法连接

接口尺寸，接口形式，协议的一致性每根线的定义，电压，电流，频率等



#### I/O数据传输的三个要求

1. 数据位置
   - 必须选择正确的设备
   - 数据必须能在该设备内寻址
   - 一旦选择正确的设备，数据位置可能就变得微不足道了
     - 从键盘获取数据
   - 位置可能需要搜索
     - 磁道需要选择和旋转
   - 位置可能不是简单的二进制数字
2. 数据传输
   - 需要指定设备
   - 传输速率因设备而异
     - 键盘最快的可能就1秒10字节，但是磁盘块可能会快很多
   - 数据可以是输出、输入
3. 同步
   - 不仅I/O速率与处理器速度差别很大，而且I/O是异步的
   - CPU只能在时钟周期间隔询问I/O状态和传输信息，I/O状态和信息在被访问时必须是稳定的
   - 对于输出设备，只有设备准备好接收数据时才必须发送数据
   - 对于输入设备，处理器只有在设备可用时才能读取数据



#### 如何在数据传输中减少定位和同步

- 不同设备的数据结构不同，设备需要翻译地址
  - 处理器选择设备，但是地址只是处理器发送给设备的一个消息
- 处理器在读取读取设备状态时可以解决同步问题
- 为了提高速度，我们需要更高效的同步方法：DMA 和 中断



#### I/O系统的可靠性、可用性和可信性

反映外设可靠性能的参数有：

- 可靠性
  - 系统从某个初始参考点开始一直连续提供服务的能力。
  - **平均无故障时间MTTF**来衡量
  - 系统中断服务的时间用**平均修复时间MTTR**来衡量
  - 系统的失效率 = MTTF的倒数
  - 如果系统中每个模块的生存期服从指数分布，则**系统整体的失效率是各部件的失效率之和**。
- 可用性
  - 系统正常工作的时间在连续两次正常服务间隔时间中所占的比率。
  - $可用性=\frac{MTTF}{MTTF+MTTR}$
  - $MTTF+MTTR$: **平均失效间隔时间MTBF**
- 可信性（不能够度量）
  - 服务的质量。即在多大程度上可以合理地认为服务是可靠的



:hand:栗子：

<img src="assets/image-20231221172118998.png" alt="image-20231221172118998" style="zoom:67%;" />

<img src="assets/image-20231221172153376.png" alt="image-20231221172153376" style="zoom:67%;" />



##### 故障、错误和失效

(1) 一个故障可能会导致一个或者多个错误；

(2) 错误通常具有以下特性：

  ◆ 错误在潜在状态和有效状态间相互转换；
  ◆ 潜在的错误可能通过激活而有效；
  ◆ 有效错误的影响可以传递，引起新的错误。

(3) 如果错误影响到部件正常的服务时，部件就发生了失效；

(4) 系统中的所有部件的故障、错误和失效均存在这样的关系。

**故障的分类：**

(1) 按故障产生的原因分：

  ◆ 硬件故障：设备失效产生的故障 
  ◆ 设计故障
  ◆ 操作故障：由于用户操作的失误引起的故障 
  ◆ 环境故障

(2) 按故障出现的周期分：

  ◆ 暂时性故障 间歇性故障 永久性故障



##### 提高系统组成部件可靠性

- 有效构建方法

  在构建系统的过程中消除故障隐患，这样建立起来的系统就不会出现故障

- 纠错方法

  在系统构建中采用容错方法

 故障避免技术
 故障容忍技术
 错误消除技术
 错误预报技术

**RAID！！！**





### 输入输出原理

输入输出系统：**处理机与主存储器之外的部分**

包括**输入输出设备、输入输出接口和输入输出软件**



#### 输入输出系统的特点

- 处理机与外界进行数据交换的通道
- 计算机系统中最具有多样性和复杂性的位置
- 软硬件组合



- 异步性
  - 输入输出系统通常没有统一的中央时钟，各个设备按照自己的时钟工作
  - 外围设备与外围设备之间能并行工作
- 实时性
  - 如果处理机提高服务不及时，可能丢失数据，或造成外围设备工作的错误
  - 对于实时控制计算机系统，如果处理机提供的服务不及时，可能造成巨大的损失，甚至造成人身伤害。
  - 对于处理机本身的硬件或软件错误：如电源故障、数据校验错、页面失效、非法指令、地址越界等，处理机必须及时处理。
  - 对不同类型的设备，必须具有与设备相配合的多种工作方式。

- 与设备无关性
  - 独立于具体设备的标准接口
  - 处理机采用统一的硬件和软件对品种繁多的设备进行管理。
  - 某些计算机系统已经实现了即插即用技术。



#### 输入输出系统的组织方式

- 针对实时性，采用层次结构的方法。
  - 最内层是输入输出处理机、输入输出通道等。
  - 中间层是标准接口。
  - 标准接口通过设备控制器与输入输出设备连接。
- 针对与设备无关性，采用分类处理的方法。
  - 面向字符的设备，如字符终端、打字机等
  - 面向数据块的设备，如磁盘、磁带、光盘等。
- 针对异步性，采用自治控制的方法。
  - 输入输出系统是独立于CPU之外的自治系统处理机与外围设备之间要有恰当的分工



#### 基本输入输出方式

##### 程序控制输入输出

状态驱动输入输出方式、应答输入输出方式、查询输入输出方式、条件驱动输入输出方式。

程序控制输入输出方式有4个特点：

1. 何时对何设备进行输入输出操作受CPU控制。
2. CPU要通过指令对设备进行测试才能知道设备的工作状态。如：闲、准备就绪、忙碌等
3. 数据的输入和输出都要经过CPU。
4. 用于连接低速外围设备，如终端、打印机等。



**简单的总线结构**

<img src="assets/image-20231221173000613.png" alt="image-20231221173000613" style="zoom:67%;" />

- 设备可以是“奴隶”，只响应I/O总线请求
- 设备可以是“主人”，启动I/O总线传输



例：一个处理机在一段时间内只能管理一台打印机。处理机执行指令的速度为1GIPS，字长32位，打印机每秒钟100个字符。
解：处理机用一条指令就能向打印机传送4个字符。因此，处理机的实际利用率只有即4千万分之一。 
$$
100/10^9\times 4＝0.25\times 10^{-7}
$$


**一个处理机管理多台外围设备**

处理机采用轮流循环测试方法，分时为各台外围设备服务

- 优点：
  - 灵活性很好。可以很容易地改变各台外围设备的优先级。

- 缺点：
  - 不能实现处理机与外围设备之间并行工作。





##### 中断输入输出方式

定义：当出现来自系统外部，机器内部，甚至处理机本身的任何例外的，或者虽然是事先安排的，但出现在现行程序的什么地方是事先不知道的事件时，CPU暂停执行现行程序，转去处理这些事件，等处理完成后再返回来继续执行原先的程序。
特点：

1. CPU与外围设备能够并行工作。
2. 能够处理例外事件。
3. 数据的输入和输出都要经过CPU。
4. 用于连接低速外围设备。



##### 直接存储器访问方式

直接存储器访问方式(DMA：Direct Memory Access)，主要用来连接高速外围设备。如磁盘存储器，磁带存储器、光盘辅助存储器，行式打印机等

<img src="assets/image-20231222085124414.png" alt="image-20231222085124414" style="zoom:70%;" />

- DMA在I/O设备和主存之间自动传输数据，中断 / 轮询完成
  - 通过内存映射寄存器编程的直接存储器存取
  - 有些系统在DMA内部使用专用处理器
  - 外围设备的访问请求直接发往主存储器，数据的传送过程不需要CPU的干预。
  - 全部用硬件实现，不需要做保存现场和恢复现场等工作。
  - DMA控制器复杂，需要设置数据寄存器、设备状态控制寄存器、主存地址寄存器、设备地址寄存器和数据交换个数计数器及控制逻辑等。
  - 在DMA方式开始和结束时，需要处理机进行管理。



DMA输入设备的工作流程如下：

- 从设备读一个字节到DMA控制器中的数据缓冲寄存器中。
- 若一个字没有装配满，则返回到上面；若校验出错，则发中断申请；若一个字已装配满，则将数据送主存数据寄存器。

- 把主存地址送主存地址寄存器，并将主存地址增值。

- 把DMA控制器内的数据交换个数计数器减１。

- 若交换个数为0，则DMA数据传送过程结束，否则回到上面



DMA输出设备的工作流程如下：

- 把主存地址送入主存地址寄存器，并启动主存储器，同时将主存地址增值。
- 将主存数据寄存器中的数据送DMA控制器的数据寄存器。

- 把数据写到输出介质上（可能要逐个字符输出）。

- 把DMA控制器内的数据交换个数计数器中的内容减１。

- 若交换个数为0，则DMA数据传送过程结束，否则回到上面。



目前使用DMA的方式：

- 周期窃取方式：
  - 在每一条指令执行结束时，CPU**测试**有没有DMA服务申请。
  - 借用CPU完成DMA工作流程。包括数据和主存地址的传送，交换个数计数器减1，主存地址的增值及一些测试判断等。
  - 周期窃取方式的**优点**是硬件结构简单，比较容易实现。
  - 缺点是在数据输入或输出过程种实际上占用了CPU的时间。
- 直接存取方式：
  - 整个工作流程全部用硬件完成。
  - 优点与缺点正好与周期窃取方式相反。

- 数据块传送方式：
  - 在设备控制器中设置一个比较大的数据缓冲存储器。设备控制器与主存储器之间的数据交换以数据块为单位，并采用程序中断方式进行。	
  - 采用数据块传送方式的外围设备有软盘驱动器、行式打印机、激光打印机、卡片阅读机、绘图仪等。



**从并行转向串行 I/O 离片**

- 并行总线的时钟速率受限于长总线上的时钟偏斜（大约100MHz）

- 驱动大量加载的总线线路需要高功率

- 中央总线仲裁器增加了每个交易的延迟，共享限制了吞吐量

- 昂贵的并行连接器和背板/电缆（所有设备都要支付成本）

- 示例：VMEbus、Sbus、ISA总线、PCI、SCSI、IDE。

点对点链接使用高级时钟/信号编码在gigabit速度运行（需要在每端大量电路）

- 较低功率，因为只有一个表现良好的负载
- 多重同时传输
- 廉价电缆和连接器（用更高的端点晶体管成本换取较低的物理布线成本），通过并行使用多个链接为每个设备定制带宽
- 示例：以太网、Infiniband、PCI Express、SATA、USB、Firewire 等。



**从总线转向Crossbar**

- 总线在那个时代发展起来，那时候电线非常昂贵且必须共享。
- 总线三态驱动器在标准单元流程中存在问题，因此用组合复用器替代。
- 交叉开关利用芯片内布线的密集度，允许多个数据传送同时进行。



### 中断系统

#### 中断源的组织

- 中断系统需要**硬件和软件**共同来实现，引起中断的各种事件称为**中断源**。

- 中断系统的复杂性实际上主要是由**中断源的多样性**引起的。

- 中断源可以来自**系统外部**，也可以来自**机器内部**，甚至**处理机**本身。

- 中断可以是硬件引起的，也可以是软件引起的。

- 把各种各样的中断源分类、分级组织好，是中断系统的关键之一。



##### 中断源的种类

- 由外围设备引起的中断：低速外围设备每传送一个字节申请一次中断；高速外围设备的前、后处理。
- 由处理机本身产生的中断：如算术溢出，除数为零，数据校验错等。
- 由存储器产生的中断：如地址越界、页面失效、访问存储器超时等。
- 由控制器产生的中断：如非法指令、堆栈溢出、时间片到、切换到特权态。

- 由总线产生的中断：输入输出总线出错,存储总线出错等。
- 实时过程控制产生的中断。
- 实时钟的定时中断。
- 多处理机系统中，从其它处理机发送来的中断。
- 程序调试过程中，由断点产生的中断。
- 硬件故障中断 电源故障中断。



##### 中断源的分类组织

- 中断源分类组织的目的：在**响应中断后能尽快找到中断入口。**
- 根据中断事件的**紧迫程度**，中断源工作速度、性质等进行分类

- 为每一类中断源分配一个硬件的中断入口，在进入这个入口之后，再通过软件找到具体的中断源。

- 可屏蔽中断与不可屏蔽中断，或称**一般中断和异常中断**。



IBM公司的机器，把中断源分为6类：

- 机器检验出错中断。由硬件或软件故障时产生。
- 程序性错误引起的中断。

- 访问管理程序中断。当用户程序执行访管指令引起的中断。

- 外部事件中断。

- 输入输出中断。

- 重新启动中断。处理机不能禁止这类中断





##### 中断优先级

- 安排中断优先顺序主要由下列因素来决定：
  - 中断源的急迫性。
  - 设备的工作速度。
  - 数据恢复的难易程度。
  - 要求处理机提供的服务量。
- 中断优先级与中断服务顺序
  - 要求：**响应速度快，灵活性好**。
  - 做法：由硬件排队器决定**中断优先级**。
- **通过软件设置中断屏蔽码改变中断服务顺序**。



:hand:：在IBM 370系列机中，把7类中断分为5个中断优先级，从高到低分别是：

1. 紧急的机器检验错误引起的中断。
2. 调用管理程序，程序性错误，可以抑制的机器检验错误引起的中断。
3. 外部事件引起的中断。
4. 外围设备的中断。
5. 重新启动引起的中断。



:hand:：某处理机共有4个中断源，中断优先级从高到低分别是：1级、2级、3级和4级。当处理机在执行主程序时，同时有3级和2级两个中断源向处理机发出中断服务请求。当处理机为2级中断源服务时又有4级中断源发出中断服务请求。当处理机为４级中断源服务时又有１级中断源发出中断服务请求：

<img src="assets/image-20231222091639730.png" alt="image-20231222091639730" style="zoom:67%;" />



#### 中断系统的软硬件分配

有些功能必须用硬件实现，有的功能必须用软件实现，而大部分功能既可以用硬件实现，也可以用软件实现。

**恰当分配中断系统的软硬件功能**，是中断系统最关键问题。

必须用硬件实现的有：

- 保存中断点和进入中断服务程序入口。
- 这两个功能相当于执行一条转子程序指令，因为中断发生在现行程序的什么地方是不确定的，不能由程序员来安排。

必须用软件实现的有：

- 中断服务和返回到中断点。
- 返回到中断点，通过执行一条中断返回指令来实现。
- 中断服务必须用软件实现，因为是“程序中断方式”。

主要考虑的两个因素：

- **中断响应时间：中断响应时间是一个非常重要的指标。**
- **灵活性：硬件实现速度快，灵活性差；软件实现正好相反。**



##### 中断处理过程

现行指令结束，且没有更紧急的服务请求。
关CPU中断。
保存断点，主要保存PC中的内容。
撤消中断源的中断请求。
保存硬件现场，主要是PSW及SP等。
识别中断源。
改变设备的屏蔽状态。
进入中断服务程序入口
保存软件现场，在中断服务程序中使用的通用寄存器等。
开CPU中断，可以响应更高级别的中断请求。
中断服务，执行中断服务程序。
关CPU中断。
恢复软件现场。
恢复屏蔽状态。
恢复硬件现场。
开CPU中断。
返回到中断点。



##### 中断响应时间

定义：从**中断源向处理机发出中断服务请求开始**，到**处理机开始执行这个中断源的中断服务程序时为止**，这一段时间称为中断响应时间。

影响中断响应时间的因素主要有4个： (前2个属于处理机设计，后2个属于中断系统)

1. 最长指令执行时间
   有些指令的执行时间很长，甚至无法预测。
2. 处理其它更紧急的任务所用时间
   如处理DMA请求等。
3. 从第一次关CPU中断到第一次开CPU中断所经历的时间
   中断系统的软件与硬件功能分配，主要就是要考虑这一段内要所的事情用软件来实现，还是用硬件来实现。
4. 通过软件找到中断服务程序入口所用时间
   主要是第1和第3两部分。其中，第1部分是指令系统设计时考虑的问题，在中断系统的设计中，主要考虑第3部分。



#### 中断源的识别方法

识别中断源的查询法

- 所有中断源共用一条中断请求线
- 处理机响应中断后都进入同一个程序入口
- 用软件找出申请中断的中断源
- 主要优点：灵活性好。主要缺点：速度慢。

<img src="assets/image-20231222092240386.png" alt="image-20231222092240386" style="zoom:67%;" />



软件排队链法

- 设置一个中断请求寄存器，每个中断源在其中占据一位，并且按照中断的优先级从高位到低的顺序排列。
- 所有中断源使用同一条公共的中断请求线，进入公共中断源服务程序入口，其过程与查询法相同。

- 在公共中断服务程序入口，用一条特殊指令读出中断请求寄存器中的内容，并根据读出的内容直接进入中断服务程序。

- 节省了用软件逐个寻找中断源的时间。



硬件排队链法

- 用硬件排队器和编码器，在所有请求中断服务的中断源中，找出具有最高优先级的中断源。
- 设置一个中断请求寄存器，每个中断源在其中中占据一位。

- 所有中断源使用同一条公共的中断请求线，进入公共中断源服务程序入口。

- 转入公共的中断服务程序后，用一条特殊指令直接读到所有请求中断服务的中断源中具有最高优先级的中断源编号。

- 特点：识别中断源的速度更快



中断向量法

- 在主存储器的固定区域中开辟出一个专用的中断向量区。
- 用硬件排队器和编码器在所有请求中断服务的中断源中，产生具有最高优先级的中断源编号。

- 隐含执行上面方法中的两条识别中断源的指令，直接通过硬件转向这个中断源的中断服务程序入口。
  不需要进入公共中断服务程序，能够实现到中断程序的最快转移



独立请求法

各个中断源使用自己独立的中断请求线。每一根中断请求线在处理机中有固定的或可编程的中断优先级。

如果同时有多个中断源请求中断服务，通过仲裁线路立即选择具有最高优先级的中断源，并向它发出中断响应信号INIT，处理机就可以立即转入这个中断源的中断服务程序。

独立请求法实际上是把分布在各个中断源内的串行排队器都集中到处理机中，从而克服了串行排队链法可靠性差的缺点，但灵活性差的缺点仍然存在。

![image-20231222092403388](assets/image-20231222092403388.png)

中断源用init信号清除中断请求信号。

不需要软件或硬件对中断源进行扫描，不需要中断源送回中断源编号或中断向量



识别中断源的分组独立请求法，把独立请求法与串行排队链法结合起来。

中断源分组：组内采用串行排队链法，组间采用独立请求法。



上面的2、3、4三种识别中断源的方法都属于串行排队链法：

- 串行排队链法的优点：
  - 识别中断源的速度比较快，特别是中断向量法。
  - 实现比较简单，中断源与处理机的连线很少。

- 串行排队链法的缺点：
  - 灵活性比较差，中断优先级是由硬件固定。不能由程序员通过软件修改。
  - 可靠性比较差，排队链串行分布在各个中断源中。一个出错，都出错。



#### 中断现场的保存和恢复

中断现场的保护和恢复分别是中断处理机过程开始和结束时必须执行的步骤，可以分为三类：

1. 程序计数器PC，必须由硬件来完成保存，可以保存在存储器固定单元或者堆栈。利用中断返回指令来恢复。
2. 当前程序状态的有关信息，包括：处理机状态字、堆栈指针、基址寄存器、中断屏蔽码等
   保存与恢复方法有：主存固定区域，压入系统堆栈、交换处理机状态字。也可以采用软件在中断服务程序中保存和恢复。
3. 软件现场：指在中断服务程序中被破坏的通用寄存器。一般采用软件来保存和恢复现场，指令系统给予适当支持。也有些处理机采用硬件来保存软件现场，如Sparc处理机。



#### 中断屏蔽

？？？？？？？？？？？



### 通道处理机

通道处理机的作用主要是在外围设备种类、数量很多的情况下把外围设备的管理工作从CPU中分离出来。

处理机与外部设备的连接方式：

- 直接连接
- 通道处理机
- 输入输出处理机



三种基本输入输出方式存在的问题：

1. CPU的输入输出负担很重，不能专心用于用户程序的计算工作。
2. 低速外围设备，每传送每个字符都由CPU执行一段程序来完成。

3. 高速外围设备的初始化、前处理和后处理等工作需要CPU来完成。

4. 大型机中的外围设备台数很多，但一般并不同时工作。让DMA控制器能被多台设备共享，提高硬件的利用率

#### 通道的作用和功能

#### 通道的工作过程

#### 通道的种类

#### 通道中的数据传送过程

#### 通道流量分析



### 输入输出处理机

#### 输入输出处理机的作用

#### 输入输出处理机的种类

#### 输入输出处理机实例

## 五、标量处理机

只有标量数据表示和标量指令系统的处理机称为标量处理机

提高指令执行速度的主要途径：

 (1) 提高处理机的工作主频
 (2) 采用更好的算法和设计更好的功能部件
 (3) 采用指令级并行技术

三种指令级并行处理机：

 (1) 流水线处理机和超流水线(Super-pipelining)处理机
 (2) 超标量(Superscalar)处理机
 (3) 超长指令字(VLIW: Very Long Instruction Word)处理机



### 流水线结构原理

**流水作业的特点：**

- 流水线不减少单个任务的耗时，增加整个工作的吞吐量
- 被最慢的阶段限制
- 速度=通道数
- 多个工作同时进行
- 不平衡的任务减少速度

**指令流水线：**把指令的解释过程分解为“分析”和“执行”两个子过程，并让这两个子过程分别用独立的分析部件和执行部件来实现。

- 理想情况：速度提高一倍

  <img src="assets/image-20231225213850770.png" alt="image-20231225213850770" style="zoom:67%;" />

- 当分析部件完成上一条指令的“分析”后，就立即将之送入执行部件，同时分析部件可以开始处理下一条指令。

- 虽然从执行一条指令的全过程来看，仍需要2∆t的时间，但从机器的输出端来看，却是每隔一个∆t就能给出一条指令的执行结果。

**流水线结构原理**：

如何加快指令的解释过程是计算机组成设计的基本任务。除了采用高速部件外，一次重叠，先行控制和流水等控制方式是常用的，意在提高指令的并行性，从而加速指令的解释过程。控制方式分类：**顺序方式、 重叠方式、 流水方式。**



计算机的各个部分几乎都可以采用：

  **(1)**指令的执行过程可以采用流水线，称为**指令流水线**。

  **(2)**运算器中的操作部件，如浮点加法器、浮点乘法器等可以采用流水线，称为**操作部件流水线**。

  **(3)**访问主存的部件可以采用**访存部件流水线**。多个计算机之间，通过存储器连接，也可以采用流水线，称为**宏流水线**。

#### 指令的重叠执行方式

##### 顺序执行方式

$$
执行n条指令的时间\quad T=\sum_{i=1}^n\left(t_{\text{取指令 }i}+t_{\text{ 分析 }i}+t_{\text{执行 }i}\right)
$$

优点：简单，节省设备；缺点：执行指令的速度慢，功能部件的利用率很低。

##### 重叠方式

在两条相近指令的解释过程中，某些不同解释阶段在时间上存在重叠部分。包括一次重叠、先行控制技术和多操作部件并行。 

###### 一次重叠

把取指令操作隐含在分析、执行指令过程中，则在任何时候只允许上条指令“执行”与下条指令“分析”相重叠。           $  T=（n+1）×t $

若执行时间不等，则实际执行时间：
$$
\begin{aligned}{T=t_{\text{分}1}+\sum_{i=2}^{n}[\max(t_{\text{分}i},t_{\text{执}i-1})]+t_{\text{执}n}}\end{aligned}
$$

###### 二次重叠执行方式

把取第k+1条指令提前到分析第k条指令同时执行

- 如果三个过程的时间相等，执行n条指令的时间为：T=(2+n)t

- 理想情况下同时有三条指令在执行

- 处理机的结构要作比较大的改变，必须采用先行控制方式

  <img src="assets/image-20231225215531524.png" alt="image-20231225215531524" style="zoom:50%;" />

采用二次重叠执行方式，必须解决两个问题：

  (1) 有独立的取指令部件、指令分析部件和指令执行部件

​    独立的控制器：存储控制器、指令控制器、运算控制器

  (2) 要解决访问主存储器的冲突问题

​    取指令、分析指令、执行指令都可能要访问存储器



**解决访存冲突的方法**：

   (1) 采用低位交叉存取方式：这种方法不能根本解决冲突问题。
	 取指令、读操作数、写结果。

  (2) 两个独立的存储器：独立的指令存储器和数据存储器。
	如果再规定，执行指令所需要的操作数和执行结果只写到通用寄存器，那么，取指令、分析指令和执行指令就可以同时进行。
    在许多高性能处理机中有独立的指令Cache和数据Cache。 这种结构被称为哈佛结构。

   (3) 采用先行控制技术。
    先行控制技术的关键是缓冲技术和预处理技术。
    缓冲技术是在工作速度不固定的两个功能部件之间设置缓冲栈，用以平滑它们的工作。
    采用了缓冲技术和预处理技术之后，运算器能够专心于数据的运算，从而大幅度提高程序的执行速度。

<img src="assets/image-20231225215730464.png" alt="image-20231225215730464" style="zoom:50%;" />



多操作部件并行：采用有多个功能部件的处理机，把ALU的多种功能分散到几个具有专门功能的部件中，这些功能部件可以并行工作，使指令流出速度大大提高。 





### 流水线技术 Pipelining 

- 空间并行性
  -  设置多个独立的操作部件
  -  多操作部件处理机
  -  超标量处理机

- 时间并行性
  -  采用流水线技术。
  -  不增加或只增加少量硬件就能使运算速度提高几倍
  -  流水线处理机
  -  超流水线处理机

#### 流水线的表示方法

连接图、时空图、预约表（主要前两种）

**简单流水线**：

流水线的每一个阶段称为**流水步、流水步骤、流水段、流水线阶段、流水功能段、功能段、流水级、流水节拍**等。一个流水阶段与另一个流水阶段相连形成**流水线**。指令从流水线一端进入，经过流水线的处理，从另一端流出。

有些复杂指令在执行阶段也采用流水线方式工作，称为操作流水线。

<img src="assets/image-20231225220247778.png" alt="image-20231225220247778" style="zoom:67%;" />

**指令流水线**：

<img src="assets/image-20231225220332027.png" alt="image-20231225220332027" style="zoom:67%;" />

一般4-12个流水段，大于等于8个为超级流水线处理机

**时空图：**

采用“时空图”表示流水线的工作过程。在时空图中，横坐标表示时间，也就是输入到流水线中的各个任务在流水线中所经过的时间。当流水线中各个流水段的执行时间都相等时，横坐标被分割成相等长度的时间段。纵坐标表示空间，即流水线的每一个流水段 

<img src="assets/image-20231225220605624.png" alt="image-20231225220605624" style="zoom:67%;" />

- 建立时间：在流水线开始时有一段流水线填入时间，使得流水线填满。
- 正常流动时间：流水线正常工作，各功能段源源不断满载工作。
- 排空时间：在流水线第一条指令结束时，其他指令还需要一段释放时间。



#### 流水线的特点

- 流水一定重叠，比重叠更苛刻。
- 一条流水线通常有多个子过程。每个子过程称为流水线的“级”或“段”。其数目称为流水线的“深度”。
- 每段有专用功能部件，各部件顺序连接。
- 流水线有建立时间、正常满载时间、排空时间。另外，流水线需要有“通过/装入时间”（第一个任务流出结果所需的时间），在此之后流水过程才进入稳定工作状态，每一个时钟周期（拍）流出一个结果。
- 流水线每一个功能段部件后面都要有一个缓冲寄存器，或称为锁存器，其作用是保存本流水段的结果，如图8所示。由于流水线中每一个流水段的延迟时间不可能绝对相等，再加上电路的延迟时间及时钟等都存在偏移，因此流水段之间传送任务时，必须通过锁存器。
- 流水线中各功能段的时间应尽量相等，否则将引起堵塞、断流，这个时间一般为一个时钟周期（拍） 。要求流水线的时钟周期不能快于最慢的流水段。另一方面，执行时间长的一个流水段将成为整个流水线的瓶颈，此时流水线中的其他功能部件就不能发挥作用。因此瓶颈问题是流水线设计中必须解决的问题。
- 只有连续不断地提供同一种任务时才能发挥流水线的效率。例如，要使浮点加法器流水线充分发挥作用，需要连续提供浮点加法运算。只有流水线完全满载时，整个流水线的效率才能得到充分发挥。
- 给出指标如最大吞吐率，为满负载最佳指标。

### 指令相关

指令相关（Instruction Dependency）是指在程序中一条指令的执行依赖于前一条或几条指令的结果的情况。在处理器的流水线执行中，指令相关会导致执行中断或延迟，影响处理器的性能

分类有：数据相关，控制相关，结构相关

#### 数据相关（Data Hazards）

在处理器的流水线执行中，后续指令依赖于前面指令的执行结果的情况。这种依赖关系导致流水线无法连续流畅地执行，因为某些操作必须等待之前的操作完成后才能开始。

假设我们需要执行指令：

1. `I1: ADD R1, R2, R3` - 将寄存器R2和R3的值相加，结果存储在R1中。
2. `I2: SUB R4, R1, R5` - 从寄存器R1的值中减去R5的值，结果存储在R4中。
3. `I3: MUL R6, R4, R7` - 将寄存器R4和R7的值相乘，结果存储在R6中。

**分类如下：**

- 先写后读（RAW, Read After Write）： 一条指令需要读取前一条指令写入的数据。
  - 例子： I1和I2之间存在RAW相关，因为I2需要使用I1计算的结果（R1的值）
- 先读后写（WAR, Write After Read）： 一条指令需要写入的数据之前被另一条指令读取。
  - 假设例子： 如果I2写入R2，而I1要读取R2，那么I1和I2之间就存在WAR相关。
- 写后写（WAW, Write After Write）： 两条指令写入相同的位置。
  - 假设例子： 如果有另一条指令I4: ADD R1, R8, R9紧跟I1，那么I1和I4之间存在WAW相关，因为它们都想写入R1。

后两种类型只会出现在异步流动流水线中

**解决方法：**

1. **数据前递（Data Forwarding/Bypassing）：**
   - **应用于RAW：** 在`I1`和`I2`的情况中，可以将`I1`计算出的结果直接从执行单元传递给`I2`，而不必等待其写回到R1。
   - <img src="assets/image-20231226104609209.png" alt="image-20231226104609209" style="zoom:50%;" />
2. **指令重排（Instruction Reordering）：**
   - 如果可能，重新安排指令的顺序，以减少指令之间的直接依赖。
   - 例如，如果`I3`不依赖于`I1`和`I2`的结果，可以先执行`I3`。
3. **流水线暂停（Pipeline Stalling）：**
   - 当检测到数据相关时，特别是在前递不可能的情况下，暂停流水线直到所需数据准备好。
   - 例如，在`I1`和`I2`的例子中，如果前递不可行，则`I2`可能需要等待直到`I1`完成写回操作。
4. **动态调度（Dynamic Scheduling）：**
   - 处理器在运行时动态地检测指令之间的依赖性，并调整指令的执行顺序。
   - 这种方法在现代处理器中常见，特别是在乱序执行环境中。



> MIPS整数流水线是指在MIPS（Microprocessor without Interlocked Pipeline Stages）架构中实现的整数指令流水线。MIPS架构是一种典型的精简指令集计算机（RISC）架构，其设计哲学注重简单、规整的指令集和高效的流水线执行。
>
> MIPS处理器的整数流水线通常被划分为几个主要阶段，每个阶段完成指令执行过程中的一部分工作。一个典型的MIPS流水线包括以下阶段：
>
> 1. **取指（Instruction Fetch, IF）：**
>    - 在这个阶段，处理器从内存中取出下一条要执行的指令。通常涉及到程序计数器（PC）的读取和更新。
> 2. **译码/寄存器取值（Instruction Decode/Register Fetch, ID）：**
>    - 在译码阶段，处理器解析指令，确定要执行的操作类型，并从寄存器文件中取出所需的操作数。
> 3. **执行/地址计算（Execute/Address Calculation, EX）：**
>    - 执行阶段根据译码阶段的结果执行算术或逻辑操作，或者计算内存访问的地址。对于分支指令，这个阶段也包括条件判断和计算跳转地址。
> 4. **访存（Memory Access, MEM）：**
>    - 如果指令涉及内存访问（如加载和存储指令），这个阶段负责实际的内存读写操作。
> 5. **写回（Write-back, WB）：**
>    - 在写回阶段，执行结果（如果有的话）被写回到寄存器文件中。对于加载指令，从内存读取的数据在这个阶段写入寄存器。
>
> MIPS流水线的设计旨在每个时钟周期内推进一个阶段，以实现高吞吐率和效率。然而，流水线设计也面临着一些挑战，如数据冒险、控制冒险和结构冒险，需要通过各种技术（如前递、流水线暂停和分支预测）来解决。



#### 控制相关（Control Hazards）

**控制相关**因为程序执行转移类指令而引起的相关。转移类指令如无条件转移、条件转移、子程序调用、中断等，它们属于分支指令，执行中可能改变程序的方向，从而造成流水线断流。

数据相关影响到的仅仅是本条指令附近少数几条指令，所以称为局部相关。而控制相关影响的范围要大得多，它会引起程序执行方向的改变，使流水线损失更多的性能，所以称为全局相关。

控制相关会使流水线的连续流动受到破坏。当执行条件转移指令时，有两种可能结果：

1. 如发生转移，将程序计数器PC的内容改变成转移目标地址；
2. 如不发生转移，只是将PC加上一个增量，指向下一条指令的地址。

> "Control Dependence Ignored"（忽略控制依赖）是在编译优化和程序并行化领域中的一个概念，尤其是在尝试提高程序执行效率的过程中。它涉及到一种假设或技术，即在某些情况下可以忽略控制依赖，以便在不改变程序意义的前提下进行更大范围的代码重组或并行化。
>
> **忽略控制依赖的动机**：
>
> - **性能优化**：通过重排指令顺序或并行执行原本依赖于控制流的指令，可以提高程序的性能。
> - **编译器优化**：编译器在优化代码时可能会选择忽略某些控制依赖，以便重新安排指令序列，减少延迟，或增加并行度。
> - **并行处理**：在多线程或多核心处理中，忽略控制依赖可以帮助更有效地利用资源，通过并行执行原本串行的代码片段。
>
> 实现方法：
>
> 实现忽略控制依赖的技术可能包括但不限于：
>
> - **谓词执行**（Predication）：将条件分支转换为条件执行的指令，这样所有路径上的指令都会执行，但只有在给定条件为真时才会影响状态。
> - **编译时分析**：静态分析代码以确定哪些控制依赖可以安全地忽略或重新排列。
> - **动态重排**：在运行时动态地决定指令的执行顺序，可能结合硬件支持。

由转移指令(占总指令的1/4)引起的相关。

##### 解决控制相关的方法：

1. **分支预测（Branch Prediction）：**
   - **原理**：提前预测分支指令的结果（是否会跳转以及跳转目标地址），并据此继续指令的取指和执行。
   - **实现**：可以是简单的静态预测（如始终预测跳转或不跳转），或复杂的动态预测（基于历史信息进行预测）。
   - 预测分支失败
     - 流水线继续照常流动，就像没发生什么似的。在知道分支结果之前，分支指令后的指令不能
       改变机器状态，或者改变了之后能够回退。
     - 若预测分支失败，则照常执行；否则，从转移目标处开始取指令执行。
   - 预测分支成功
     - 假设分支转移成功，并开始从分支目标地址处取指令执行。
     - 起作用的前题：先知道分支目标地址，后知道分支是否成功。
   - 想办法提高猜测的正确率，可以有效提高流水线效率
2. **延迟分支（Delayed Branch）：**
   - **原理**：在分支指令后安排几条无关的指令执行，这些指令无论分支结果如何都要执行。
   - **实现**：编译器或汇编程序员负责在分支指令后安排适当的指令。
3. **双指令缓冲：**
   - 同时运行判断语句的两个分支，使用正确的那一个
4. **分支目标缓冲区（Branch Target Buffer, BTB）：**
   - **原理**：缓存分支指令的目标地址，使得在再次遇到相同的分支指令时，可以快速获取跳转地址。
   - **实现**：硬件中实现一个专门的缓存，存储分支指令的地址及其对应的跳转目标地址和分支结果。
5. **分支历史表（Branch History Table, BHT）：**
   - **原理**：记录分支指令的历史行为（跳转或不跳转），用于动态分支预测。
   - **实现**：在硬件中维护一个表格，记录每个分支指令的历史行为，以指导未来的预测。
6. **动态预测技术：**
   - **原理**：使用更复杂的算法，如基于局部或全局历史的预测算法，以提高分支预测的准确性。
   - **实现**：例如，两级自适应训练（Two-Level Adaptive Training）或全局历史表（Global History Table）等。
7. **乱序执行和指令重排：**
   - **原理**：允许处理器乱序执行指令，并在保证数据一致性的前提下调整指令的完成顺序。
   - **实现**：在处理器中实现复杂的逻辑，以允许乱序执行和动态调度。



##### 延迟分支

延迟分支（Delayed Branch）是一种用于处理流水线中控制相关的技术，尤其是在分支指令导致的流水线停顿（Branch Stall）中。延迟分支的核心思想是在分支决定是否跳转以及跳转到哪里之前，执行一个或多个“延迟槽”（Delay Slot）中的指令。这样做的目的是在分支指令的影响被解析出来之前，利用原本会空闲的流水线周期。

延迟分支所使用的填充指令通常来源于：

1. **从前调度：**
   - 被调度的指令必须与分支无关
2. **分支指令紧随其后的指令**：
   - 编译器会尝试重排代码，将一些与分支无关的指令移动到延迟槽中。这些指令在分支无论如何都会执行，不受分支结果的影响。
3. **编译器专门插入的无操作指令（NOPs）**：
   - 如果找不到合适的指令来填充延迟槽，编译器可能会插入NOP指令。这虽然不增加额外的有效工作，但至少可以避免错误的行为。
4. **代码中其他位置的无关指令**：
   - 编译器可能会进行更复杂的代码分析，从程序的其他部分找到可以安全执行的指令，并将它们移动到延迟槽中。



移动指令到延迟槽的方式

1. **简单移动**：直接将分支后紧接着的指令移动到延迟槽中。
2. **复杂重排**：进行更全面的代码分析和重排，找到可以安全移动到延迟槽的指令。
3. **循环展开**：在循环结构中，将循环体内的某些指令移动到循环条件的分支延迟槽中。
4. **与其他优化技术结合**：如和指令流水线优化、循环变换等结合，以找到更多合适的指令。





##### 动态分支预测

动态分支预测是一种在现代微处理器中常用的技术，用于提高处理器执行指令时的效率。这种技术旨在预测程序中的条件分支（如if-else语句或循环）将如何执行，以减少因等待分支结果而导致的处理器空闲时间。

**动态分支预测的基本原理**

动态分支预测依赖于在运行时收集的信息，以预测分支指令的行为。它的核心思想是基于分支指令的历史行为来预测它未来的行为。这种方法认为程序的行为具有一定的模式，通过观察过去的行为来预测未来的行为。

**动态分支预测必须解决两个问题**：

- 如何记录一个分支操作的历史
  - 仅仅记录最近一次或最近几次的分支历史；
  - 记录分支成功的目标地址；
  - 记录分支历史和分支目标地址，相当于前面两种方式的结合；
  - 记录分支目标地址的一条或若干条指令。  
- 决定预测的走向。

**如何预测**

- 如果预测正确，则不会产生分支惩罚，因为我们获取了正确的指令
- 如果预测错误（错误预测），则必须从流水线中清除错误指令
- 最简单的预测器：始终预测未执行的指令
- 动态分支预测器在分支历史表（BHT）（又称分支预测缓冲区）中跟踪过去的行为

**关键组件和技术**

1. **分支历史表（Branch History Table, BHT）**：这是一种硬件机制，用于记录每个分支指令的最近几次执行情况（是否发生了跳转）。
2. **分支目标缓冲区（Branch Target Buffer, BTB）**：存储分支指令的目标地址，当再次遇到相同的分支指令时，可以快速获取跳转地址。
3. **分支预测算法**：例如二位饱和计数器（Two-bit Saturating Counter），它为每个分支维护一个小型状态机，根据最近几次的跳转或不跳转历史来预测下一次的行为。
4. **全局历史记录**：考虑整个程序的分支历史，而不仅仅是单个分支的历史。这可以通过全局历史表（Global History Table）等实现。
5. **局部历史记录**：仅考虑特定分支的历史。

:hand:例子：

1. 只有1个预测位的分支预测缓冲 

  - 索引：分支指令地址的低位。

  - 存储区：1位的分支历史记录位，又称为预测位，记录该指令最近一次分支是否成功。

    - “0”记录分支不成功 
    - “1”记录分支成功

  - 状态转换图 

    <img src="assets/image-20231226115027385.png" alt="image-20231226115027385" style="zoom:33%;" />

  - 分支预测错误时，预测位就被修改，并且需要恢复现场，程序从分支指令处重新执行。 

  - 缺点：只要预测出错，往往是连续两次而不是一次。

2. 采用两个预测位

  - 必须有两次连续预测错误才更改

    <img src="assets/image-20231226122138385.png" alt="image-20231226122138385" style="zoom:67%;" />

3. n 位分支预测缓冲

  - 采用n位计数器，则计数器的值在0到2n-1之间：
         当计数器的值大于或等于最大值的一半（2n-1）时，
         预测下一次分支成功；否则预测下一次分支不成功。
  - 预测位的修改和两位预测时相同：
         当分支成功时计数器的值加1，不成功时减1。
  - 研究表明：n位分支预测的性能和两位分支预测差不多，因而
        大多数处理器都只采用两位分支预测。

#### 结构相关（Structure Hazards）

**结构冒险解决方法**：

- 当两个指令同时需要相同的硬件资源时，就会产生结构危害
  - 能否在硬件上通过拖延新指令直到旧指令用完资源来解决问题
- 通过在设计中添加更多的硬件，总是可以避免结构上的危险
  - 例如，如果两个指令同时需要一个端口到内存，可以通过增加第二个端口到内存来避免危险

#### 异常和中断

##### 精确中断与非精确中断

精确中断（Precise Interrupts）与非精确中断（Imprecise Interrupts）是处理器在面对中断和异常时的两种不同处理机制。

**精确中断（Precise Interrupts）**

精确中断指的是处理器能够在任何指令的执行点准确地报告程序的状态。当发生精确中断时，处理器保证以下条件：

1. **所有先于中断点的指令都已完全执行**：这意味着所有影响程序状态的操作都完成了。
2. **所有后续指令尚未执行**：即中断点之后的指令不会影响程序状态。
3. **程序计数器（PC）精确地指向引起中断的指令**：这允许程序在处理中断后恢复执行。
4. **所有的寄存器和内存状态都能反映出中断发生时的确切情况**。

精确中断对于调试、错误恢复和多线程程序的正确性至关重要。它确保在中断处理后，程序能够无缝地从中断点继续执行。

**非精确中断（Imprecise Interrupts）**

非精确中断是指处理器不能保证上述所有条件，特别是在现代高性能处理器使用复杂技术（如乱序执行、规格执行）时。在非精确中断发生时：

1. **一些先于中断点的指令可能尚未完成**。
2. **一些后续指令可能已经部分或完全执行**。
3. **程序计数器可能不精确指向引起中断的指令**。

非精确中断使得错误恢复和程序调试变得更加困难，因为中断时的程序状态可能不完全清晰。

##### 处理中断的四种可能的办法

方法1：忽略这种问题，当非精确处理

- 原来的supercomputer的方法
- 但现代计算机对 IEEE 浮点标准的异常处理，虚拟存储的异常处理要求必须是精确中断。

方法2：缓存操作结果，直到早期发射的指令执行完。

- 当指令运行时间较长时，缓冲区较大
- Future file
  - 缓存执行结果，按指令序确认
- history file
  - 尽快确认
  - 缓存区存放原来的操作数，如果异常发生，回卷到合适的状态

方法3：以非精确方式处理，用软件来修正

- 为软件修正保存足够的状态
- 让软件仿真尚未执行完的指令的执行
  - Instruction 1 – A 执行时间较长，引起中断的指令
  - Instruction 2, instruction 3, ….instruction n-1 未执行完的指令
  - Instruction n    已执行完的指令
  - 由于第n条指令已执行完，希望中断返回后从第n+1条指令开始执行，如果我们保存所有的流水线的PC值，那么软件可以仿真Instruction1 到Instruction n-1 的执行

方法4：暂停发射，直到确定先前的指令都可无异常的完成，再发射下面的指令。

- 在EX段的前期确认（MIPS流水线在前三个周期中）

  

### 流水线分类

流水线（Pipeline）在计算机架构中是一种重要的概念，用于提高处理器的性能。流水线可以按照不同的方式进行分类，每种分类侧重于流水线的某个特定特征或设计理念。以下是一些常见的流水线分类方式及其类别：

#### 按照流水线的级别来分

- 处理机级流水线，又称为指令流水线 (Instruction Pipelining)，例如：在采用先行控制器的处理机中，各功能部件之间的流水线

  <img src="assets/image-20231226110240480.png" alt="image-20231226110240480" style="zoom:50%;" />

- 部件级流水线（操作流水线），把处理机的算术逻辑部件分段，使得各种数据类型的操作能够进行流水。如浮点加法器流水线

  <img src="assets/image-20231226110317649.png" alt="image-20231226110317649" style="zoom:50%;" />

- 宏流水线 (Macro Pipelining)，每个处理机对同一个数据流的不同部分分别进行处理，它是指由两个以上的处理机串行地对同一数据流进行处理，每个处理机完成一项任务。

  <img src="assets/image-20231226110343597.png" alt="image-20231226110343597" style="zoom:50%;" />

#### 单功能流水线与多功能流水线

- 单功能流水线：只能完成一种固定功能的流水线
  - Cray-1计算机中有12条；YH-1计算机有18条；Pentium有一条5段的定点和一条8段的浮点流水线；PentiumⅢ有三条指令流水线，其中两条定点指令流水线，一条浮点指令流水线。
- 多功能流水线：流水线的各段通过不同连接实现不同功能
  - Texas公司的ASC计算机中的8段流水线，能够实现：定点加减法、定点乘法、浮点加法、浮点乘法、逻辑运算、移位操作、数据转换、向量运算等。

#### 按照指令处理的方式分类

##### a. 静态流水线（Static Pipeline）

- **定义**：每个流水线阶段在每个时钟周期内**执行固定的操作**，流水线的行为在编译时就已经确定。
- **特点**：结构简单，易于实现，但在面对复杂指令或数据依赖时效率较低。

##### b. 动态流水线（Dynamic Pipeline）

- **定义**：流水线能够根据运行时的情况动态调整，如动态指令调度和乱序执行。
- **特点**：能更有效地处理各种冒险和依赖，提高执行效率，但设计复杂。

#### 按照指令执行的顺序分类

##### a. 直线流水线（Linear Pipeline）

- **定义**：指令按照固定的顺序逐阶段进行处理，每个阶段固定。
- **特点**：设计简单，适合顺序执行的任务。

##### b. 超标量流水线（Superscalar Pipeline）

- **定义**：在每个时钟周期内可以同时发射和完成多条指令。
- **特点**：能够提高吞吐率，但需要复杂的指令调度和冒险管理机制。

##### c. 乱序执行流水线（Out-of-Order Pipeline）

- **定义**：指令可以根据数据依赖和资源可用性乱序执行。
- **特点**：提高资源利用率和执行效率，但设计和实现相对复杂。

#### 按照流水线的结构分类

##### a. 线性结构流水线（Linear Structured Pipeline）

- **定义**：流水线的每个阶段固定，按顺序排列。
- **特点**：易于理解和实现，但在某些阶段可能成为瓶颈。

##### b. 循环流水线（Cyclic Pipeline）

- **定义**：流水线的末端与开始相连，形成一个循环，允许连续的数据处理。
- **特点**：适用于重复性任务，如数字信号处理，但需要管理循环中的数据依赖。

#### 按照功能分类

##### a. 整数流水线（Integer Pipeline）

- **定义**：专门处理整数运算的流水线。
- **特点**：通常简单高效，用于处理基本的算术和逻辑操作。

##### b. 浮点流水线（Floating Point Pipeline）

- **定义**：专门处理浮点运算的流水线。
- **特点**：比整数流水线复杂，用于执行浮点数计算。

##### c. 图形流水线（Graphics Pipeline）

- **定义**：专为图形处理设计的流水线，如在GPU中。
- **特点**：优化了图形和图像处理任务，结构和操作针对图形处理进行特化。



### 线性流水线的性能分析

1. 吞吐率（Throughput）

     - 定义：单位时间内流水线完成指令的数量。

   - 计算方法：通常是每个时钟周期完成的指令数。对于完全流水线，理论上每个时钟周期可以完成一条指令，但实际吞吐率可能因冒险和延迟而降低。


   - $TP=n/T_k$，$TP$为吞吐里，n为指令数，$T_k$为完成n个指令所用时间


   - 若各段执行时间相等，则输入连续任务情况下完成n个连续任务需要的总时间为：$T_k=(k+n-1)D_t$，k为流水线段数，$D_t$为完成一条指令所需时间


   - 最大吞吐率：$TP_\max=\underset{n\to\infty}{\operatorname*{Lim}}\frac n{(k+n-1)\Delta t}=\frac1{\Delta t}$


   - 各段执行时间不相等、输入连续任务情况下：吞吐率为


$$
\begin{aligned}TP=\frac{n}{\sum_{i=1}^kt_i+(n-1)\max(\Delta t_1,\Delta t_2,\cdot\cdot\cdot,\Delta t_k)}\end{aligned}
$$

2. 延迟（Latency）

     - 定义：一条指令从开始到结束所需的时间。

     - 计算方法：通常以时钟周期数计算。在流水线中，延迟等于流水线的深度（阶段数）乘以时钟周期时间。


3. 流水线效率（Pipeline Efficiency）

     - 定义：流水线资源的利用率。

     - 计算方法：有效执行时间与总执行时间的比率。如果存在流水线停顿（如由于数据冒险），效率会下降。

     - 若各段时间相等，则各段的效率$e_i$相等，即$e_1=e_2=\dots=e_k=\Delta t_o/T_{流水}$

       整个流水线的效率：$\begin{aligned}E=\frac{n\Delta t_0}{T_\text{流水}} = \frac n { k + n - 1 }&=\frac1{1+\frac{k-1}n}\end{aligned}$

       从时－空图上看，效率实际上就是 n 个任务所占的时空区与 k 个段总的时空区之比，即：

   $$
   E=\frac{n\text{个任务占用的时空区}}{ k\text{个流水段的总的时空区}} = \frac { T _ 0 }{ k \cdot T _ k}
   $$

   - 若各段时间相等，输入n个连续任务流水线的效率为：$E=\frac{k\cdot n\cdot\Delta t}{k\cdot(k+n-1)\cdot\Delta t}=\frac n{k+n-1}$

     最高效率为：$\begin{array}{rcl}E_\mathrm{max}=Lim\frac n{k^2+2n^2-1}=1\end{array}$

   - 各流水段执行时间不等，输入n个连续任务流水线的效率为：
     $$
     E=\frac{n\cdot\sum_{i=1}^k\Delta t_i}{k\cdot[\sum_{i=1}^k\Delta t_i+(n-1)\cdot\max(\Delta t_1,\Delta t_2,\cdots,\Delta t_k)]}
     $$

   - 


4. 速度提升比（Speedup Ratio）

     - 定义：流水线实现相比于非流水线执行的速度提升。


     - 计算方法：非流水线执行时间与流水线执行时间的比率。理想情况下，速度提升与流水线的阶段数相等。$S = 顺序执行时间T_0 / 流水线执行时间T_k$


     - 各段执行时间相等，输入连续任务情况下加速比为：
       $$
       S=\frac{k\cdot n\cdot\Delta t}{(k+n-1)\Delta t}=\frac{k\cdot n}{k+n-1}
       $$


     - 最大加速比：$S_\max=\underset{n\to\infin}{\operatorname*{Lim}}\frac{k\cdot n}{k+n-1}=k$


     - **各段执行时间不等**，输入连续任务情况下实际加速比为：
       $$
       S=\frac{n\cdot\sum_{i=1}^{\kappa}\Delta t_i}{\sum_{i=1}^{k}\Delta t_i+(n-1)\cdot\max(\Delta t_1,\Delta t_{2,\cdots,\Delta t_k})}
       $$


5. 流水线利用率（Pipeline Utilization）

     - 定义：流水线在执行过程中被有效利用的程度。

     - 计算方法：考虑流水线各阶段的利用情况。如果某些阶段经常空闲，说明流水线利用率不高。




### 调度

假想这么一个情况，lw 指令后面紧跟着一连串的计算指令，且这些计算指令和 lw 指令没有关系，在这种情况下，如果lw指令发生 data cache miss，那么它可能会被卡在访存阶段几十上百个周期，而因为处理器是顺序执行的，所以后面的一连串计算指令也都被阻塞住。这里面就出现了一个问题，lw 后面的一连串指令完全不依赖lw指令，但是却因为 lw 指令而没办法继续执行。在理想情况下，我们肯定希望在 lw 指令阻塞的时候，别的可以执行的指令继续执行，不要受 lw 的影响。但是这在一个顺序执行的处理器中是做不到的，顺序执行的处理器只能一个接着一个地执行，如果想要实现“继续执行”，即后面的指令“绕过” lw 指令继续执行，那么就需要处理器支持乱序。

#### 静态指令调度

静态调度(static scheduling)是由优化的编译程序来完成，其基本思想是重排指令序列，拉开具有数据相关的有关指令间的距离。由于是用编译程序判测潜在的数据相关，并在程序运行之前完成调度，故称为静态调度。

#### 动态调度

- 通过忽略 "顺序 "程序中人为的串行限制，实现更多并行性，也称为失序问题（OOO-issue）：指令不需要按照原来的程序顺序执行

优点：

1. **提高资源利用率**：动态调度可以更有效地利用处理器资源，如算术逻辑单元（ALU）、寄存器等，减少空闲时间。
2. **提升性能**：通过减少指令间的依赖和冲突，减少阻塞和等待时间，提高执行效率。
3. **更好的适应性**：能够根据当前系统的负载和环境条件灵活调整，适应多变的工作条件。
4. **容错和负载均衡**：在发现错误或性能瓶颈时，能够动态地重新分配任务，实现负载均衡。

#### 记分牌ScoreBoard

记分牌算法是 CDC 公司在上个世纪提出的一个乱序执行算法，合理使用记分牌算法，就可以让多配置流水的处理器实现乱序执行。首个应用记分牌算法的处理器是CDC公司在上个世纪六十年代研发的 CDC 6600，实际上 CDC 6600 不能说是一个处理器，因为 CDC 6600 是一个几吨重的超级计算机。



#### Tomasulo算法

Tomasulo算法是一种用于处理器流水线的动态调度算法，由Robert Tomasulo在IBM为System/360设计的浮点单元中首次实现。这个算法的主要目的是通过乱序执行和寄存器重命名来减少指令之间的数据依赖，从而提高执行效率。

##### 关键特性：

1. **寄存器重命名**：通过使用保留站（Reservation Stations）来消除虚假的数据依赖。
2. **乱序执行**：允许指令根据操作数的可用性而非程序顺序执行。
3. **动态调度**：指令的执行不是由程序代码的静态顺序决定的，而是由数据的可用性和功能单元的空闲状态决定的。
4. **公共数据总线（CDB, Common Data Bus）**：用于广播执行结果，使得其他等待这些结果的指令能够及时获取。

##### 应用：

Tomasulo算法主要应用于超标量处理器和一些向量处理器中，它允许这些处理器更有效地实现指令级并行（Instruction-Level Parallelism, ILP）。

### 流水线的表示图



### 各种处理机

<img src="https://img2020.cnblogs.com/blog/2190912/202010/2190912-20201030112944650-45555698.png" alt="img" style="zoom:50%;" />

#### 超流水线处理机

- 指令执行时序
- 典型处理机结构
- 超流水线处理机性能

两种定义：

- 一个周期内能够分时发射多条指令的处理机称为超流水线处理机。
- 指令流水线有8个或更多功能段的流水线处理机称为超流水线处理机。

提高处理机性能的不同方法：

- 超标量处理机是通过增加硬件资源为代价来换取处理机性能的。
- 超流水线处理机则通过各硬件部件充分重叠工作来提高处理机性能。

两种不同并行性：

- 超标量处理机采用的是空间并行性
- 超流水线处理机采用的是时间并行性



指令执行时序

每隔1/n个时钟周期发射一条指令，流水线周期为1/n个时钟周期
在超标量处理机中，流水线的有些功能段还可以进一步细分
例如：ID功能段可以再细分为译码、读第一操作数和读第二操作数三个流水段。也有些功能段不能再细分，如WR功能段一般不再细分。因此有超流水线的另外一种定义：有8个或8个以上流水段的处理机称为超流水线处理机



每个时钟周期分时发送3条指令的超流水线

<img src="assets/image-20231226123705923.png" alt="image-20231226123705923" style="zoom:50%;" />

##### 性能分析

指令级并行度为(1,n)的超流水线处理机，执行N条指令所的时间为：$T\left(1,n\right)=(k+\frac{N-1}n)\Delta t$

超流水线处理机相对于单流水线普通标量处理机的加速比为：
$$
S\left(1,n\right)=\frac{T\left(1,1\right)}{T\left(1,n\right)}=\frac{(k+N-1)\Delta t}{(k+\frac{N-1}n)\Delta t}=\frac{n(k+N-1)}{nk+N-1}
$$


#### 超标量超流水线处理机

把超标量与超流水线技术结合在一起，就成为超标量超流水线处理机

超标量超流水线处理机在一个时钟周期内分时发射指令n次，每次同时发射指令m条，每个时钟周期总共发射指令m × n条。

<img src="assets/image-20231227104726196.png" alt="image-20231227104726196" style="zoom:50%;" />

##### 性能分析

指令级并行度为(m,n)的超标量超流水线处理机，连续执行N条指令所需要的时间为：$T(m,n)=(k+\frac{N-m}{m\cdot n})\Delta t$

超标量超流水线处理机相对于单流水线标量处理机的加速比为：
$$
\begin{aligned}
&\begin{aligned}S(m,n)=\frac{S(1,1)}{S(m,n)}=\frac{(k+N-1)\Delta t}{(k+\frac{N-m}{mn})\Delta t }\end{aligned} \\
&S(m,n)=\frac{m\cdot n\cdot(k+N-1)}{m\cdot n\cdot k+N-m}
\end{aligned}
$$


## 六、向量处理机

- 向量处理机是解决数值计算问题的一种高性能计算机结构
- 向量处理机一般都采用流水线结构，有多条流水线并行工作
- 向量处理机通常属大型或巨型机，也可以用微机加一台向量协处理器组成
- 一般向量计算机中包括有一台高性能标量处理机
- 必须把要解决的问题转化为向量运算，向量处理机才能充分发挥作用

向量处理机

提高流水性能方法：

- 增加流水线段数，以减少Δt；
- 每个时钟同时启动多条指令；
- 减少相关，减少功能变换次数，增加处理指令条数。

向量操作特点：

- 1.向量元素间操作相互独立，且为相同操作。
- 2.相当于标量循环，对指令带宽的访问要求不高。
- 3.可采用多体交叉存储器，减少访存延迟。

  向量操作很适合于流水处理或并行处理。



## 七、互联网络

由开关元件按照一定的拓扑结构和控制方式构成的网络，用于实现计算机系统内部多个处理机或多个功能部件之间的相互连接

- 并行计算机架构核心
- 许多权衡
  - 优雅数学结构
  - 
