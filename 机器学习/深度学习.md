# 深度学习



均方误差不能用于分类



前馈神经网络：都和前面的节点相连，和同层没有相连

只要有足够多的神经元，可以以任何精度逼近任何函数

隐层激活函数：ReLU的系列函数

只有加上非线性的变换才有意义



ReLU的系列函数，在负数段给一个非常小的斜率



Sigmiod梯度趋近于0，饱和现象，改进：取正切



初始化方法也很重要



优化的时候陷入局部最小：
加一个速度 动量 



找假设空间

### 多层感知机

反向传播：计算梯度

梯度下降：使用梯度学习参数