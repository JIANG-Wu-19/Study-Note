# 数据结构与算法

## 绪论

### 基本概念

**数据元素：**组成数据的，有一点意义的基本单位

**数据项：**一个元素可以由若干数据项组成，是不可分割的最小单位

**数据对象：** **性质相同**的数据元素的组合，是数据的子集

**数据结构：**不同元素不是独立存在的，而是存在特定的关系，我们将这些关系成为结构

数据结构关注的是**数据元素之间的关系**和操作，不关心数据的具体内容

### 逻辑结构与物理结构

逻辑结构：数据对象中数据元素之间的关系，分为以下四种

**1. 集合结构：** 数据元素除了同属于一个集合外，它们之间没有任何其他关系

**2. 线性结构：** 一对一关系

**3. 树状结构：** 数据元素之间存在一对多的层次关系

**4. 图形结构：** 多对多的关系



物理结构（存储结构）：数据的逻辑结构再计算机中的存储形式

**顺序存储，链式存储，索引存储，散列存储**



## 算法

算法：解决特定问题求解步骤的一种描述

1. 有穷性：在执行有穷部后结束，且每一步都可以在有穷时间完成
2. 确定性：相同输入能得到相同输出
3. 可行性：有零个或多个输入，有一个或多个输出

### 算法效率的度量问题

#### 事后统计法

利用计算器对不同算法编制的程序运行时间进行比较，缺陷在于计算机硬件不同，没法比较，缺陷较大；有些算法不能事后统计，比如导弹发射。

#### 事前分析估计法

利用问题规模n来度量，考虑最高次项即可



### 算法时间复杂度

#### 算法时间复杂度的定义

$T(n)$ 是关于问题规模 $n$ 的函数，$T(n)=O(f(n))$。它表示随着问题规模n的增大，算法执行时间的增长率和$f(n)$的增长率相同，成为算法的渐进时间复杂度



用大写$O()$来体现算法时间复杂度的方法，我们称为**大O记法**

随着n的增大，$T(n)$增长最慢的称为最优算法

---

推导大O：

1. 用1代替所有加法常数
2. 只保留最高次项
3. 把最高次项系数变成1
3. 相乘的时候都保留



$O(1)<O(\log_2 n)<O( n \log_2 n)<O(n^2)<O(n^3$$)<O(2^n)<O(n!)<O(n^n)$

常对幂指接

如何从代码中推导时间复杂度：

1. 顺序执行的代码只影响常数项，不用考虑
2. 只用挑循环中的一个基本操作去分析他的执行次数与n的关系
3. 如果有多层嵌套循环，只需要关注最深层循环嵌套了几次

#### 三种时间复杂度

最坏、最好、平均：关注最坏和平均就行

#### 求时间复杂度的方法

时间复杂度是算法效率的度量，算法的时间复杂度与问题的输入规模有关

##### 递归树

<img src="assets/image-20230611083445191-16864436874611.png" alt="image-20230611083445191" style="zoom: 80%;" />

##### 主定理

在计算时间复杂度时，主定理（Master Theorem）是一种常用的方法，尤其适用于分治算法的递归时间复杂度的求解。主定理提供了一种直接分析递归关系的方法，以确定算法的渐近时间复杂度。主定理主要适用于以下形式的递归关系：

$$
T(n) = aT\left(\frac{n}{b}\right) + f(n)
$$
其中：
- $ a $ 是每次递归调用的分支数；
- $ \frac{n}{b} $ 是每个子问题的规模；
- $ f(n) $ 是在分解和合并阶段花费的时间。

主定理有三种情况，根据 $ f(n) $ 的增长速度与 $ n^{\log_b{a}} $ 的关系来判断时间复杂度。

1. 如果 $ f(n) = O(n^c) $ 且 $ c < \log_b{a} $，则
   $$ T(n) = \Theta(n^{\log_b{a}}) $$
   
2. 如果 $ f(n) = \Theta(n^{\log_b{a}}) $，则
   $$ T(n) = \Theta(n^{\log_b{a}} \log n) $$
   
3. 如果 $ f(n) = \Omega(n^c) $ 且 $ c > \log_b{a} $，并且 $ af\left(\frac{n}{b}\right) \leq kf(n) $ 对于某个常数 $ k < 1 $ 和足够大的 $ n $，则
   $$ T(n) = \Theta(f(n)) $$



假设有一个递归关系：$$ T(n) = 2T\left(\frac{n}{2}\right) + n $$

1. 首先，确定主定理中的参数：
   - $ a = 2 $
   - $ b = 2 $
   - $ f(n) = n $

2. 计算 $ n^{\log_b{a}} $：
   - $ \log_b{a} = \log_2{2} = 1 $
   - 因此， $ n^{\log_b{a}} = n^1 = n $

3. 比较 $ f(n) $ 与 $ n^{\log_b{a}} $：
   - 这里， $ f(n) = n $ 和 $ n^{\log_b{a}} = n $
   - 所以 $ f(n) = \Theta(n^{\log_b{a}}) $

根据主定理的情况2，我们可以得出：
$$
T(n) = \Theta(n \log n)
$$


### 算法空间复杂度

是指执行当前算法需要占用多少内存空间，我们通常用「空间复杂度」来描述。



## 线性表

### 线性表的定义和基本操作

零个或多个**相同类型**的数据元素的**有限序列**，一对一，有前有后

在负载的线性表中，一个数据元素可以由若干数据项组成

读取的时候时间复杂度都是 $O(1)$，插入或删除时，时间复杂度都是$O(n)$

数据元素的位数是从1开始的

优点：

1. 无需为表中元素之间的逻辑关系而增加额外的储存空间
2. 可以快速地存取表中任一位置的元素

缺点：

1. 插入和删除操作需要移动大量元素
2. 当线性表长度变化较大，难以确定存储空间容量

#### 基本操作

初始化表，销毁操作，插入操作，删除操作，按值查找，按位查找

### 线性表的顺序存储结构

逻辑上相邻的数据元素物理上也相邻

### 线性表的链式存储结构（链表）

链式结构中，除了要存储数据元素信息外，还要存储它的后继元素的存储地址

数据域：存储数据元素信息的域

指针域：存储直接后继位置的域

n个结点链成一个链表，即为线性表的链式存储结构

链表中的第一个节点的存储位置叫头指针

最后一个节点指针为“空”，通常用NULL表示

### 静态链表

用结构体数组实现，数组中包含数据元素和cur元素

### 循环链表

让最后一个指针指向头指针

### 双向链表

结构体中有两个指针，一个指前面一个指后面



## 四、栈与队列

#### 栈

##### 栈的定义

栈(stack)是限定仅在表尾进行插入和删除操作的线性表

栈顶：允许插入和删除的一端称为栈顶

栈底：另一端



##### 栈的抽象数据类型

理论上线性表的操作特性它都有，可是由于它的特殊性，插入和删除操作改名为push和pop



##### 两栈共享空间

为了节约内存空间，可以用一个数组来存放两个栈，这样需要一些技巧，比如建立以下数组

```c++
typedef struct
{
	int date[MAXSIZE];
	int top1;
	int top2;
}
```

当`top1+1=top2`时栈满



##### 中缀表达式转后缀表达式

两个栈实现，数字栈和符号栈



#### 队列

先进后出，一段进行插入（队尾），另一段只允许删除（队头）

##### 顺序储存不足

如果保证队头下标为0，则删除的时间复杂度为*O(n)*，插入为*O(1)*

如果不保证对头下标为0，则插入删除都为*O(1)*，但容易产生假溢出情况



## 五、串

0个或多个字符串组成的有序序列，又叫字符串



### KMP算法

题目：http://acm.hdu.edu.cn/showproblem.php?pid=1711

先对模式串建立next数组

```c++
#include <vector>
#include <iostream>
#include <string>

// 构建next数组
void buildNext(const std::string& pattern, std::vector<int>& next) {
    int m = pattern.length(), j = 0;
    next[0] = -1; // next数组初始化
    int t = -1;
    while (j < m - 1) {
        if (t < 0 || pattern[j] == pattern[t]) {
            ++j;
            ++t;
            if (pattern[j] != pattern[t]) {
                next[j] = t;
            } else {
                next[j] = next[t];
            }
        } else {
            t = next[t];
        }
    }
}

// KMP搜索算法
int KMP(const std::string& text, const std::string& pattern) {
    int n = text.length();
    int m = pattern.length();
    std::vector<int> next(m);
    buildNext(pattern, next); // 构建next数组
    int i = 0, j = 0;
    while (i < n) {
        if (j < 0 || text[i] == pattern[j]) { // 匹配成功或j为-1
            i++;
            j++;
        } else {
            j = next[j]; // 根据next数组跳转j
        }
        if (j == m) { // 完整匹配
            return i - m; // 返回匹配起始索引
        }
    }
    return -1; // 未找到匹配
}

int main() {
    std::string text = "ABABDABACDABABCABAB";
    std::string pattern = "ABABCABAB";
    int matchIndex = KMP(text, pattern);
    if (matchIndex != -1) {
        std::cout << "Pattern found at index " << matchIndex << std::endl;
    } else {
        std::cout << "Pattern not found" << std::endl;
    }
    return 0;
}
```



## 六、树

### 二叉树

左右区分 只有两个子树

特殊：

斜树：单偏

满二叉树：所以分支都有子树

完全二叉树：按顺序编号，同一层一定从左往右满的



### 遍历二叉树

前序，中序，后序，其实就是转换print的位置



### 哈夫曼树：

带权路径长度WPL最小的二叉树称为哈夫曼树

如何构造：在集合中选择权值最小的两个数，较小放左边，两数权重之和N1加入集合之中，重复网上种树

### 平衡二叉查找树（AVL）

AVL树中，任一节点对应的两棵子树的最大高度差为1，因此它也被称为**高度平衡树**。查找、插入和删除在平均和最坏情况下的时间复杂度都是$\displaystyle O(\log {n})$

**左右子树的高度相差不超过 1 的树为平衡二叉树。**

#### 定义

**平衡二叉查找树**：简称平衡二叉树。由前苏联的数学家 **A**delse-**V**elskil 和 **L**andis 在 1962 年提出的高度平衡的二叉树，根据科学家的英文名也称为 AVL 树。它具有如下几个性质：

1. 可以是空树。
2. 假如不是空树，任何一个结点的左子树与右子树都是平衡二叉树，并且高度之差的绝对值不超过 1。

#### 节点结构

```c++
typedef struct AVLNode *Tree;

typedef int ElementType;

struct AVLNode{

    int depth; //深度，这里计算每个结点的深度，通过深度的比较可得出是否平衡

    Tree parent; //该结点的父节点

    ElementType val; //结点值

    Tree lchild;

    Tree rchild;

    AVLNode(int val=0) {
        parent = NULL;
        depth = 0;
        lchild = rchild = NULL;
        this->val=val;
    }
};
```

#### 平衡因子

**定义：**某节点的左子树与右子树的高度(深度)差即为该节点的平衡因子（BF,Balance Factor），平衡二叉树中不存在平衡因子大于 1 的节点。在一棵平衡二叉树中，节点的平衡因子只能取 0 、1 或者 -1，分别对应着左右子树等高，左子树比较高，右子树比较高。

#### AVL树插入时的失衡与调整

插入一个节点后，可能会导致树不平衡，这时候就要从在新插入的结点向上查找，以第一个平衡因子的**绝对值**超过 1 的结点为根的子树称为最小不平衡子树。

可能会有很多子树失衡，但我们只需要调整最小不平衡子树

#### AVL树的四种插入方式

1. 左孩子的左子树插入节点

   一次右旋

2. 右孩子的右子树插入节点

   一次左旋

3. 左孩子的右子树插入节点

   先对左孩子进行左旋，再对当前节点右旋

4. 右孩子的左子树插入节点

   先对右孩子进行右旋，再对当前节点左旋

#### 代码实现

好的，我们来一步步地实现一个AVL树的基本框架。AVL树是一种自平衡二叉搜索树，它的每一个节点存储了一个平衡因子，这个平衡因子是左子树的高度和右子树的高度的差。对于任何一个节点，这个平衡因子的绝对值不能超过1。如果在插入或删除操作之后平衡因子超过了1，就需要通过旋转操作来恢复平衡。

以下是AVL树实现的核心部分，包括节点定义、插入、删除、以及旋转操作。

##### AVL树节点的定义

首先，我们定义AVL树的节点，每个节点包含数据、左右子节点的指针，以及一个表示节点高度的变量。

```cpp
struct AVLNode {
    int key;
    AVLNode *left;
    AVLNode *right;
    int height;

    AVLNode(int k) : key(k), left(nullptr), right(nullptr), height(1) {}
};
```

##### 计算节点高度

我们需要一个辅助函数来计算节点的高度，因为在进行旋转操作时需要知道子树的高度。

```cpp
int getHeight(AVLNode *N) {
    if (N == nullptr)
        return 0;
    return N->height;
}
```

##### 更新节点高度

在每次插入或删除操作之后，我们需要更新经过的节点的高度。

```cpp
void updateHeight(AVLNode *N) {
    N->height = 1 + max(getHeight(N->left), getHeight(N->right));
}
```

##### 平衡因子

计算节点的平衡因子，它是左子树高度减去右子树高度。

```cpp
int getBalance(AVLNode *N) {
    if (N == nullptr)
        return 0;
    return getHeight(N->left) - getHeight(N->right);
}
```

##### 旋转操作

为了保持树的平衡，我们需要实现四种旋转操作：左旋、右旋、左右旋和右左旋。

- **右旋**:

```cpp
AVLNode *rightRotate(AVLNode *y) {
    AVLNode *x = y->left;
    AVLNode *T2 = x->right;

    // Perform rotation
    x->right = y;
    y->left = T2;

    // Update heights
    updateHeight(y);
    updateHeight(x);

    // Return new root
    return x;
}
```

- **左旋**:

```cpp
AVLNode *leftRotate(AVLNode *x) {
    AVLNode *y = x->right;
    AVLNode *T2 = y->left;

    // Perform rotation
    y->left = x;
    x->right = T2;

    // Update heights
    updateHeight(x);
    updateHeight(y);

    // Return new root
    return y;
}
```

##### 插入操作

插入是AVL树中最关键的操作之一，因为它需要在插入新节点后检查树是否失衡，并进行相应的旋转操作来恢复平衡。

```cpp
AVLNode* insert(AVLNode* node, int key) {
    // 1. Perform the normal BST insertion
    if (node == nullptr)
        return(new AVLNode(key));

    if (key < node->key)
        node->left = insert(node->left, key);
    else if (key > node->key)
        node->right = insert(node->right, key);
    else // Equal keys are not allowed in BST
        return node;

    // 2. Update height of this ancestor node
    updateHeight(node);

    // 3. Get the balance factor of this ancestor node to check whether
    // this node became unbalanced
    int balance = getBalance(node);

    // If this node becomes unbalanced, then there are 4 cases

    // Left Left Case
    if (balance > 1 && key < node->left->key)
        return rightRotate(node);

    // Right Right Case
    if (balance < -1 && key > node->right->key)
        return leftRotate(node);

    // Left Right Case
    if (balance > 1 && key > node->left->key) {
        node->left = leftRotate(node->left);
        return rightRotate(node);
    }

    // Right Left Case
    if (balance < -1 && key < node->right->key) {
        node->right = rightRotate(node->right);
        return leftRotate(node);
    }

    /* return the (unchanged) node pointer */
    return node;
}
```

### 红黑树

红黑树是一种自平衡的二叉查找树，是一种高效的查找树。它可在 O(logN) 时间内完成查找、增加、删除等操作。

红黑树性质：

- 节点是红色或黑色。
- 根是黑色。
- 所有叶子都是黑色（叶子是NIL节点）。
- 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。）
- 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点（简称黑高）。



## 七、图

### 图的存储结构

##### 1.邻接矩阵

利用一维数组来存储节点信息，用二维数组来存储图的信息

无向图：二维数组会是一个对称矩阵

想知道某一个顶点的度，就是这个顶点$V_i$代表的是第$i$列的元素之和

有向图：$V_1到V_2$有弧，得到$arc[1][0]=1$

有向图讲究入度和出度，列元素之和为入度，行元素之和为出度



每条边上有权重的图叫网，则邻接矩阵的定义
$$
arc[i][j]=\left\{
                \begin{array}{ll}
                  W_{ij}，若(v_i,v_j)\in E或<v_i,v_j>\in E\\
                  0，若i=j\\
                  \infin，其他
                \end{array}
              \right.
$$


因为权重可能为0，所以其他情况时不要用0



##### 2.邻接表

数组与链表结合的存储方法

表节点为数组，后面链上边表节点，无向图中后面会链上所有有边节点，有向图中只链进入的节点

带权重的可以在边表节点中加weight数据域

不管是邻接表还是逆邻接表，有向图中对于出度和入读的计算总有一个需要遍历整个数组



##### 3.十字链表

顶点表:

| data | firstin | firstout |
| ---- | ------- | -------- |

边表节点：

| tailvex | headvex | headlink | taillink |
| ------- | ------- | -------- | -------- |

tailvex:指的是弧起点

firstin指向headvex

##### 4.邻接多重表

##### 5.边集数组



### 图的遍历

##### 深度优先算法（DFS）

简单来说就是一个递归的过程，单独存储一个visit数组作为以访问过的节点，

以邻接矩阵存储时，查找每个顶点的邻接点需要$O(n^2)$的时间，而邻接表做存储结构时，取决于顶点和边的数量，需要$O(n+e)$的时间，



##### 广度优先算法（BFS）

队列！！！

搜寻完一个节点后把他的下一层节点加入队列



BFS和DFS在时间复杂度上没有太多区别，选取怎样的方法取决于你要干啥



##### 最小生成树

###### 普利姆（Prim）算法

```c
void MiniSpanTree(Graph G) {
	int min, i, j, k
	int index[MAXVEX];					//存储下标，当前低价格下的起始节点
	int lowcost[MAXVEX];				//到此节点的最低消费
	index[0] = 0;
	lowcost[0] = 0;
	for (i = 1; i < G.num; i++) {			//初始化，把0到每个节点的权数载入
		lowcost[i] = G.arc[0][i];
		index[i] = 0;
	}
	for (i = 0; i < G.num; i++) {			//最小生成树的生成过程
		min = INFINTY;
		j = 1;
		k = 0;
		while (j < G.num) {				//寻找当前最小权数
			if (lowcost[j] != 0 && lowcost[j] < min) {
				min = lowcost[j];
				k = j;					//获得准备去的下标
			}
			j++
		}

		lowcost[k] = 0;					//lowcost=0说明此节点已载入
		for (j = 1; j < G.num; j++) {		//刷新新的最短距离
			if (lowcost[j] != 0 && lowcost[j] > G.arc[k][j]) {
				lowcost[j] = G.arc[k][j];	//如果此节点没有为0，且有更短到此节点的距离
				index[j] = k;}}}
	}
```



###### 克鲁斯卡尔（Kruskal）算法

利用边集数组，从小到大的权重编号依次排列，难点在于如何排除重复的节点



并查集：主要作用是判断某一个节点是否属于某棵树，其方法就是不断的合并树，让一个树的根节点成为另一颗树的子树，在此算法中的parent数组和Find函数就是此数据结构的应用

```c
int main MiniSpanTree_Kruskal(MGraph G)
{
	int n,m,i;
	Edge edge[MAXEDGE];
	int parent[MAXNODE];
	//省略把Edge顺次排序的代码
	
	for(i=0;i<MAXNODE;i++)
		parent[i]=0;			//初始化所有树的根
	for(i=0;i<MAXEDGE;i++)
	{
	    m=Find(edge,edge[i]->begin);
		n=Find(edge,edge[i]->end);
		if(m!=n)
		{
			parent[n]=m;		//合并树
		}
		printf("(%d,%d) %d\n",edge[i].begin,edge[i].end,edge[i].weight);
	}
}
int Find(int *parent,int i){
	while(parent[i]!=0)
	{
		i=parent[i];			//寻找根节点
	}
	return i;
}
```

### 并查集

1. 查找根节点
2. 不同则合并
3. 矮的树放在低位

可以证明这样构造并查集，树的深度不会超过$$log_2N$$

4. 顺便压缩路径

这样树的深度不会超过 $$lgN$$
